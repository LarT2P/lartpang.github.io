<!DOCTYPE html>













<html class="theme-next pisces" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">



  
  
  <link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css">




  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-center-simple.min.css?v=1.0.2" rel="stylesheet">




  
  
  <link rel="stylesheet" media="all" href="/lib/Han/dist/han.min.css?v=3.3">




<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=6.5.0" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.5.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.5.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.5.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.5.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '6.5.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="在之前的三篇文章中，我尝试了使用python爬虫实现的对于特定站点的《剑来》小说的爬取，对于豆瓣的短评的爬取，也有对于爬取的短评数据进行的词云展示，期间运用了不少的知识，现在是时间回顾一下。在此之后，我会再关注一些爬虫框架的使用，以及更多的爬虫的优化方法，争取做到尽量多的吸收新知识，巩固旧知识。 在参考文章爬虫（1）--- Python网络爬虫二三事的基础上，我写了这篇文章。 这篇文章主要的目">
<meta name="keywords" content="python">
<meta property="og:type" content="article">
<meta property="og:title" content="关于近期爬虫学习的总结">
<meta property="og:url" content="https://plart.pw/langs/python/spyder_end/index.html">
<meta property="og:site_name" content="失乐园">
<meta property="og:description" content="在之前的三篇文章中，我尝试了使用python爬虫实现的对于特定站点的《剑来》小说的爬取，对于豆瓣的短评的爬取，也有对于爬取的短评数据进行的词云展示，期间运用了不少的知识，现在是时间回顾一下。在此之后，我会再关注一些爬虫框架的使用，以及更多的爬虫的优化方法，争取做到尽量多的吸收新知识，巩固旧知识。 在参考文章爬虫（1）--- Python网络爬虫二三事的基础上，我写了这篇文章。 这篇文章主要的目">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/3471485-097f1343b6952165.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/3471485-6a9cfc5e33421cbd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/3471485-097f1343b6952165.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:updated_time" content="2018-07-13T12:43:37.697Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="关于近期爬虫学习的总结">
<meta name="twitter:description" content="在之前的三篇文章中，我尝试了使用python爬虫实现的对于特定站点的《剑来》小说的爬取，对于豆瓣的短评的爬取，也有对于爬取的短评数据进行的词云展示，期间运用了不少的知识，现在是时间回顾一下。在此之后，我会再关注一些爬虫框架的使用，以及更多的爬虫的优化方法，争取做到尽量多的吸收新知识，巩固旧知识。 在参考文章爬虫（1）--- Python网络爬虫二三事的基础上，我写了这篇文章。 这篇文章主要的目">
<meta name="twitter:image" content="http://upload-images.jianshu.io/upload_images/3471485-097f1343b6952165.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">



  <link rel="alternate" href="/atom.xml" title="失乐园" type="application/atom+xml">




  <link rel="canonical" href="https://plart.pw/langs/python/spyder_end/">



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>关于近期爬虫学习的总结 | 失乐园</title>
  











  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta custom-logo">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">失乐园</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <h1 class="site-subtitle" itemprop="description">代码与机器</h1>
      
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    
  
  
  
  

  

    <a href="https://github.com/lartpang" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewbox="0 0 250 250" style="fill: #222; color: #fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a>



    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  
    <div class="reading-progress-bar"></div>
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://plart.pw/langs/python/spyder_end/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Lart Pang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="失乐园">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">关于近期爬虫学习的总结
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2017-08-20 21:36:59" itemprop="dateCreated datePublished" datetime="2017-08-20T21:36:59+08:00">2017-08-20</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2018-07-13 20:43:37" itemprop="dateModified" datetime="2018-07-13T20:43:37+08:00">2018-07-13</time>
              
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/编程与生活/" itemprop="url" rel="index"><span itemprop="name">编程与生活</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="post-meta-item-icon">
            <i class="fa fa-eye"></i>
             阅读次数： 
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        <p>在之前的三篇文章中，我尝试了使用python爬虫实现的对于特定站点的《剑来》小说的爬取，对于豆瓣的短评的爬取，也有对于爬取的短评数据进行的词云展示，期间运用了不少的知识，现在是时间回顾一下。在此之后，我会再关注一些爬虫框架的使用，以及更多的爬虫的优化方法，争取做到尽量多的吸收新知识，巩固旧知识。</p>
<p>在参考文章<a href="http://www.jianshu.com/p/0bfd0c48457f" target="_blank" rel="noopener">爬虫（1）--- Python网络爬虫二三事</a>的基础上，我写了这篇文章。</p>
<p><strong>这篇文章主要的目的有两个，收集新知识，并用之丰富旧知识，巩固旧知识。</strong></p>
<h1 id="关于爬虫背后的这一节是主要是http的概要下一节是我的一些总结">关于爬虫背后的（这一节是主要是http的概要，下一节是我的一些总结）</h1>
<p>要想不限于代码表面，深入理解爬虫，就得需要了解一些关于网络的知识。</p>
<h2 id="http-协议">HTTP 协议</h2>
<blockquote>
<p>HTTP（Hypertext Transfer Protocol）是应用级协议，它适应了分布式超媒体协作系统对灵活性及速度的要求。它是一个一般的、无状态的、基于对象的协议。</p>
</blockquote>
<p>可以参考的文章：</p>
<p><strong>想要细致了解协议的可以查看</strong>：</p>
<ul>
<li><a href="http://man.chinaunix.net/develop/rfc/RFC1945.txt" target="_blank" rel="noopener">中文 HTTP/1.0 RFC文档目录</a></li>
<li><a href="http://www.blogjava.net/zjusuyong/articles/304788.html" target="_blank" rel="noopener">深入理解HTTP协议（转）</a></li>
<li><a href="https://www.cnblogs.com/li0803/archive/2008/11/03/1324746.html" target="_blank" rel="noopener">HTTP协议详解（真的很经典）</a></li>
<li><a href="http://tools.jb51.net/table" target="_blank" rel="noopener">HTTP请求方法大全&amp;HTTP请求头大全HTTP状态码大全HTTP Content-type 对照表</a></li>
</ul>
<h3 id="一些术语">一些术语</h3>
<ul>
<li>请求（request）：HTTP的请求消息（在第五节定义）</li>
<li>响应（response）：HTTP的回应消息（在第六节定义）</li>
<li>资源（resource）：网络上可以用URI来标识的数据对象或服务。URI有许多名字，如WWW地址、通用文件标识（Universal Document Identifiers）、通用资源标识（Universal Resource Identifiers），以及最终的统一资源定位符（Uniform Resource Locators (URL)）和统一资源名（URN）。</li>
<li>实体（entity）：可被附在请求或回应消息中的特殊的表示法、数据资源的表示、服务资源的回应等，由实体标题（entity header）或实体主体（entity body）内容形式存在的元信息组成。</li>
<li>客户端（client）：指以发出请求为目的而建立连接的应用程序。</li>
<li>用户代理（user agent）：指初始化请求的客户端，如浏览器、编辑器、蜘蛛（web爬行机器人）或其它终端用户工具。用户代理请求标题域包含用户原始请求的信息，这可用于统计方面的用途。通过跟踪协议冲突、自动识别用户代理以避免特殊用户代理的局限性，从而做到更好的回应。虽然没有规定，用户代理应当在请求中包括此域。</li>
<li>服务器（server）：指接受连接，并通过发送回应来响应服务请求的应用程序。</li>
<li>代理（proxy）：同时扮演服务器及客户端角色的中间程序，用来为其它客户产生请求。请求经过变换，被传递到最终的目的服务器，在代理程序内部，请求或被处理，或被传递。代理必须在消息转发前对消息进行解释，而且如有必要还得重写消息。代理通常被用作经过防火墙的客户端出口，用以辅助处理用户代理所没实现的请求。 <img src="http://upload-images.jianshu.io/upload_images/3471485-097f1343b6952165.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></li>
</ul>
<p><em>任何指定的程序都有能力同时做为客户端和服务器。我们在使用这个概念时，不是看程序功能上是否能实现客户及服务器，而是看程序在特定连接时段上扮演何种角色（客户或服务器）。同样，任何服务器可以扮演原始服务器、代理、网关、隧道等角色，行为的切换取决于每次请求的内容。</em></p>
<h3 id="简单流程">简单流程</h3>
<p>HTTP协议是基于<strong>请求/回应</strong>机制的。客户端与服务器端建立连接后，以请求方法、URI、协议版本等方式向服务器端发出请求，该请求可跟随包含请求修饰符、客户信息、及可能的请求体（body）内容的MIME类型消息。服务器端通过状态队列（status line）来回应，内容包括消息的协议版本、成功或错误代码，也跟随着包含服务器信息、实体元信息及实体内容的MIME类型消息。</p>
<p>绝大多数HTTP通讯<em>由用户代理进行初始化</em>，并通过它来组装请求以获取存储在一些原始服务器上的资源。</p>
<p>一次HTTP操作称为一个事务，综上，其工作过程可分为四步：</p>
<ol type="1">
<li>首先客户机与服务器需要建立连接。只要单击某个超级链接，HTTP的工作开始。</li>
<li>建立连接后，客户机发送一个请求给服务器，请求方式的格式为：统一资源标识符（URL）、协议版本号，后边是MIME信息包括请求修饰符、客户机信息和可能的内容。</li>
<li>服务器接到请求后，给予相应的响应信息，其格式为一个状态行，包括信息的协议版本号、一个成功或错误的代码，后边是MIME信息包括服务器信息、实体信息和可能的内容。</li>
<li>客户端接收服务器所返回的信息通过浏览器显示在用户的显示屏上，然后客户机与服务器断开连接。</li>
</ol>
<p>如果在以上过程中的某一步出现错误，那么产生错误的信息将返回到客户端，有显示屏输出。对于用户来说，这些过程是由HTTP自己完成的，用户只要用鼠标点击，等待信息显示就可以了。</p>
<h3 id="http-消息http-message">HTTP 消息（HTTP Message）</h3>
<p>HTTP消息由客户端到服务器的请求和由服务器到客户端的回应组成。</p>
<pre><code>HTTP-message   = Simple-Request             ; HTTP/0.9 messages
                    | Simple-Response
                    | Full-Request          ; HTTP/1.0 messages
                    | Full-Response</code></pre>
<p>完整的请求（Full-Request）和完整的回应（Full-Response）都使用<code>RFC822</code>中实体传输部分规定的消息格式。两者的消息都可能包括标题域（headers，可选）、实体主体（entity body）。实体主体与标题间通过空行来分隔（即CRLF前没有内容的行）。</p>
<pre><code>Full-Request        = Request-Line
                        *( General-Header
                        | Request-Header
                        | Entity-Header )
                        CRLF
                        [ Entity-Body ]

Full-Response       = Status-Line           
                        *( General-Header
                        | Response-Header   
                        | Entity-Header )   
                        CRLF
                        [ Entity-Body ]         </code></pre>
<p>（想要了解更多，可以前往<a href="http://man.chinaunix.net/develop/rfc/RFC1945.txt" target="_blank" rel="noopener">中文 HTTP/1.0 RFC文档目录</a> ） # 代码实现的流程</p>
<p>从我之前的代码中可以从一些方法中看出，我们利用<code>urllib</code>库，实际上完成了请求，并接受了响应。通过我们自己构造（例如添加headers）或者使用默认的请求信息，利用了<code>urllib</code>库的<code>request</code>模块的<code>Request()</code>方法构造请求，利用<code>urlopen()</code>方法接受响应返回的页面代码。</p>
<p>至于我们的爬虫工作的过程，在这里盗用(http://www.jianshu.com/p/0bfd0c48457f）一张图片：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3471485-6a9cfc5e33421cbd.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p>
<h1 id="爬虫是一个综合性的工具">爬虫是一个综合性的工具</h1>
<p>在实现爬虫的过程中，为了实现我们的目的，我们借助了各种各样的工具。浏览器的开发者工具，正则表达式，以及python的各种功能库。可谓是无所不用其极。但是，对于这些工具，我们实际上用到的功能，目前来看，其实并不多，核心代码就是那点而已，所以说，抽离出汇总起来，日后重新使用，一旦对于这个工具不再熟悉，回过头来看这些小小的片段，总是会省下很多的时间。</p>
<p>所以，这篇文章的核心内容就要来了。</p>
<h2 id="获取url">获取URL</h2>
<p>这里可以借助浏览器的<code>产看网页源代码</code>，<code>查看元素</code>等开发者工具，且快捷键一般是<code>F12</code>。</p>
<h2 id="获取页面及异常处理">获取页面及异常处理</h2>
<p>常用的是利用<code>urllib</code>库。在python3中，没有了原来2中的<code>urllib2</code>，而是用<code>urllib</code>包含了。</p>
<p>主要是用<code>urllib.request.Request()</code>&amp;<code>urllib.request.urlopen()</code></p>
<p><a href="https://docs.python.org/3.0/library/urllib.request.html" target="_blank" rel="noopener">urllib.request</a></p>
<blockquote>
<p>urllib is a package that collects several modules for working with URLs:</p>
</blockquote>
<pre><code>urllib.request  
    for opening and reading URLs
urllib.error 
    containing the exceptions raised by urllib.request
urllib.parse 
    for parsing URLs
urllib.robotparser 
    for parsing robots.txt files</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.error</span><br><span class="line"><span class="keyword">import</span> traceback</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">url = <span class="string">"..."</span></span><br><span class="line"><span class="keyword">try</span>: </span><br><span class="line">    request = urllib.request.Request(url)</span><br><span class="line">    html = urllib.request.urlopen(request).read().decode(<span class="string">""</span>)<span class="comment"># 按情况解码</span></span><br><span class="line">    print(html) </span><br><span class="line"><span class="keyword">except</span> urllib.error.URLError <span class="keyword">as</span> error_1: </span><br><span class="line">    <span class="keyword">if</span> hasattr(error_1,<span class="string">"code"</span>): </span><br><span class="line">        print(<span class="string">"URLError异常代码："</span>) </span><br><span class="line">        print(error_1.code) </span><br><span class="line">    <span class="keyword">if</span> hasattr(error_1,<span class="string">"reason"</span>): </span><br><span class="line">        print(<span class="string">"URLError异常原因："</span>) </span><br><span class="line">        print(error_1.reason)</span><br><span class="line"><span class="keyword">except</span> urllib.error.HTTPError <span class="keyword">as</span> error_2: </span><br><span class="line">    print(<span class="string">"HTTPError异常概要："</span>)</span><br><span class="line">    print(error_2)</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> error_3: </span><br><span class="line">    print(<span class="string">"异常概要："</span>) </span><br><span class="line">    print(error_3) </span><br><span class="line">    print(<span class="string">"---------------------------"</span>) </span><br><span class="line">    errorInfo = sys.exc_info() </span><br><span class="line">    print(<span class="string">"异常类型："</span>+str(errorInfo[<span class="number">0</span>])) </span><br><span class="line">    print(<span class="string">"异常信息或参数："</span>+str(errorInfo[<span class="number">1</span>])) </span><br><span class="line">    print(<span class="string">"调用栈信息的对象："</span>+str(errorInfo[<span class="number">2</span>])) </span><br><span class="line">    print(<span class="string">"已从堆栈中“辗转开解”的函数有关的信息："</span>+str(traceback.print_exc()))</span><br><span class="line"></span><br><span class="line">作者：whenif</span><br><span class="line">链接：http://www.jianshu.com/p/<span class="number">0</span>bfd0c48457f</span><br><span class="line">來源：简书</span><br><span class="line">著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</span><br></pre></td></tr></table></figure>
<blockquote>
<p>URLError 通常，URLError在没有网络连接(没有路由到特定服务器)，或者服务器不存在的情况下产生。</p>
<p>HTTPError 首先我们要明白服务器上每一个HTTP 应答对象response都包含一个数字“状态码”，该状态码表示HTTP协议所返回的响应的状态，这就是HTTPError。比如当产生“404 Not Found”的时候，便表示“没有找到对应页面”，可能是输错了URL地址，也可能IP被该网站屏蔽了，这时便要使用代理IP进行爬取数据。</p>
<p>两者关系</p>
<p>两者是父类与子类的关系，即 <strong>HTTPError是URLError的子类</strong>，HTTPError有异常状态码与异常原因，URLError没有异常状态码。所以，我们在处理的时候，不能使用URLError直接代替HTTPError。同时，Python中所有异常都是基类Exception的成员，所有异常都从此基类继承，而且都在exceptions模块中定义。如果要代替，必须要判断是否有状态码属性。</p>
</blockquote>
<p>异常处理有还有<code>else</code>&amp;<code>finally</code>可以选择。</p>
<h2 id="伪装浏览器">伪装浏览器</h2>
<p>添加头信息。可以在浏览器的开发者工具中的网路选项卡中点击对应的html页面查看请求报文和相应报文信息。一般的，只需添加用户代理信息即可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line">url = <span class="string">'http://www.baidu.com'</span></span><br><span class="line"><span class="comment"># 构造方法1</span></span><br><span class="line">headers = &#123;<span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.3; Win64; x64; rv:55.0) Gecko/20100101 Firefox/55.0'</span>&#125;</span><br><span class="line">request = urllib.request.Request(url, headers = headers)</span><br><span class="line">data = urllib.request.urlopen(request).read().decode(<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造方法2</span></span><br><span class="line">headers=(<span class="string">"User-Agent"</span>, <span class="string">"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36"</span>) </span><br><span class="line">opener = urllib.request.build_opener()</span><br><span class="line">opener.addheaders = [headers]</span><br><span class="line"><span class="comment"># # 打开方法1</span></span><br><span class="line">data = opener.open(url, timeout=<span class="number">3</span>).read().decode(<span class="string">'utf-8'</span>)</span><br><span class="line"><span class="comment"># 打开方法2</span></span><br><span class="line">urllib.request.install_opener(opener)</span><br><span class="line">data = urllib.request.urlopen(url).read().decode(<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">print(data)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">urllib</span>.<span class="title">request</span>.<span class="title">Request</span><span class="params">(url[, data][, headers][, origin_req_host][, unverifiable])</span></span></span><br></pre></td></tr></table></figure>
<p>data 数据可以是指定要发送到服务器的附加数据的字符串，如果不需要这样的数据，则为None。目前HTTP请求是唯一使用数据的请求; 当提供数据参数时，HTTP请求将是POST而不是GET。 数据应该是标准的 <em>application/x-www-form-urlencoded</em> 格式。<code>urllib.parse.urlencode()</code>函数采用映射或2元组的序列，并以此格式返回一个字符串。</p>
<p>headers 应该是一个字典，并且将被视为使用每个键和值作为参数调用 <code>add_header()</code>。 这通常用于“欺骗”用户代理头，浏览器使用它来识别自己 - 一些HTTP服务器只允许来自普通浏览器的请求而不是脚本。</p>
<h2 id="时间问题">时间问题</h2>
<h3 id="超时重连">超时重连</h3>
<p>有时候网页请求太过频繁，会出现长时间没有响应的状态，这时候一般需要设置超时重连。下面是一个例子片段</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"></span><br><span class="line">url = <span class="string">"..."</span></span><br><span class="line">NET_STATUS = <span class="keyword">False</span></span><br><span class="line"><span class="keyword">while</span> <span class="keyword">not</span> NET_STATUS:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = urllib.request.urlopen(url, data=<span class="keyword">None</span>, timeout=<span class="number">3</span>)</span><br><span class="line">        html = response.read().decode(<span class="string">'GBK'</span>)</span><br><span class="line">        print(<span class="string">'NET_STATUS is good'</span>)</span><br><span class="line">        <span class="keyword">return</span> html</span><br><span class="line">    <span class="keyword">except</span> socket.timeout:</span><br><span class="line">        print(<span class="string">'NET_STATUS is not good'</span>)</span><br><span class="line">        NET_STATUS = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以直接设置全局超时进行捕获，用的还是`socket.timeout`异常</span></span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"></span><br><span class="line">timeout = <span class="number">3</span></span><br><span class="line">socket.setdefaulttimeout(timeout)</span><br></pre></td></tr></table></figure>
<h3 id="线程延迟">线程延迟</h3>
<p>线程推迟（单位为秒），避免请求太快。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line">time.sleep(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<h2 id="页面解析">页面解析</h2>
<p>目前掌握的方法是使用正则表达式和bs库。当然，之后会了解下<code>XPath</code>，这个也提供了一种搜索的思路。</p>
<h3 id="正则匹配">正则匹配</h3>
<p>这个用的函数并不多。有两种书写方式，面向对象和</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">pattern = re.compile(<span class="string">'[a-zA-Z]'</span>)</span><br><span class="line">result_list = pattern.findall(<span class="string">'as3SiOPdj#@23awe'</span>)</span><br><span class="line">print(result_list)</span><br><span class="line"></span><br><span class="line"><span class="comment"># re.search 扫描整个字符串并返回第一个成功的匹配。 </span></span><br><span class="line">searchObj = re.search( <span class="string">r'(.*) are (.*?) .*'</span>, <span class="string">"Cats are smarter than dogs"</span>, re.M|re.I)</span><br><span class="line">print(searchObj.group())<span class="comment"># Cats are smarter than dogs</span></span><br><span class="line">print(searchObj.group(<span class="number">1</span>))<span class="comment"># Cats</span></span><br><span class="line">print(searchObj.groups())<span class="comment"># ('Cats', 'smarter')</span></span><br></pre></td></tr></table></figure>
<p><a href="www.runoob.com/python3/python3-reg-expressions.html">python3正则表达式</a></p>
<h3 id="beautifulsoup4">beautifulsoup4</h3>
<p><a href="http://www.jb51.net/article/109782.htm" target="_blank" rel="noopener">Python利用Beautiful Soup模块搜索内容详解</a></p>
<p>我个人感觉，这个库的使用，主要难点在于搜索时的麻烦。我觉得比较好用的是方法<code>find()</code>&amp;<code>find_all()</code>&amp;<code>select()</code>。</p>
<p>使用 <code>find()</code> 方法会从搜索结果中返回第一个匹配的内容，而 <code>find_all()</code> 方法则会返回所有匹配的项，返回列表。</p>
<p><code>select()</code>中可以使用CSS选择器。很方便可以参考浏览器开发者工具。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment"># 可以获取验证码图片地址并下载图片</span></span><br><span class="line">soup = BeautifulSoup(response_login, <span class="string">"html.parser"</span>)</span><br><span class="line">captchaAddr = soup.find(<span class="string">'img'</span>, id=<span class="string">'captcha_image'</span>)[<span class="string">'src'</span>]</span><br><span class="line">request.urlretrieve(captchaAddr, <span class="string">"captcha.jpg"</span>)</span><br><span class="line">...</span><br><span class="line">totalnum = soup.select(<span class="string">"div.mod-hd h2 span a"</span>)[<span class="number">0</span>].get_text()[<span class="number">3</span>:<span class="number">-2</span>]</span><br></pre></td></tr></table></figure>
<h2 id="文件读写">文件读写</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 要读取非UTF-8编码的文本文件，需要给open()函数传入encoding参数</span></span><br><span class="line"><span class="keyword">with</span> open(filename, <span class="string">'w+'</span>) <span class="keyword">as</span> open_file:</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遇到有些编码不规范的文件，你可能会遇到UnicodeDecodeError，因为在文本文件中可能夹杂了一些非法编码的字符。遇到这种情况，open()函数还接收一个errors参数，表示如果遇到编码错误后如何处理。最简单的方式是直接忽略</span></span><br><span class="line"><span class="keyword">with</span> open(filename, <span class="string">'r'</span>, encoding=<span class="string">'gbk'</span>, errors=<span class="string">'ignore'</span>) <span class="keyword">as</span> open_file:</span><br><span class="line">    all_the_text = open_file.read([size])</span><br><span class="line">    list_of_all_the_lines = open_file.readlines()</span><br><span class="line">    open_file.write(all_the_text)</span><br><span class="line">    open_file.writelines(list_of_text_strings)</span><br></pre></td></tr></table></figure>
<h2 id="登录信息">登录信息</h2>
<p>我们构造好 POST 请求，这一旦发送过去, 就登陆上了服务器, 服务器就会发给我们 Cookies。继续保持登录状态时，就需要借助相关的库的方式，可以简化处理。</p>
<p>Cookies 是某些网站为了辨别用户身份、进行 session 跟踪而储存在用户本地终端上的数据(通常经过加密)。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> parse</span><br><span class="line"><span class="keyword">from</span> http <span class="keyword">import</span> cookiejar</span><br><span class="line"></span><br><span class="line">main_url = <span class="string">'...'</span></span><br><span class="line">formdata = &#123;</span><br><span class="line">    <span class="comment"># 看网站post页面需求</span></span><br><span class="line"></span><br><span class="line">    <span class="string">"form_email"</span>:<span class="string">"你的邮箱"</span>,</span><br><span class="line">    <span class="string">"form_password"</span>:<span class="string">"你的密码"</span>,</span><br><span class="line">    <span class="string">"source"</span>:<span class="string">"movie"</span>,</span><br><span class="line">    <span class="string">"redir"</span>:<span class="string">"https://movie.douban.com/subject/26934346/"</span>,</span><br><span class="line">    <span class="string">"login"</span>:<span class="string">"登录"</span></span><br><span class="line">&#125;</span><br><span class="line">user_agent = <span class="string">'Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.94 Safari/537.36'</span></span><br><span class="line">headers = &#123;<span class="string">'User-Agnet'</span>: user_agent, <span class="string">'Connection'</span>: <span class="string">'keep-alive'</span>&#125;</span><br><span class="line"></span><br><span class="line">cookie = cookiejar.CookieJar()</span><br><span class="line">cookie_support = request.HTTPCookieProcessor(cookie)</span><br><span class="line">opener = request.build_opener(cookie_support)</span><br><span class="line">data = parse.urlencode(formdata).encode(<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">req_ligin = request.Request(url=main_url, data=data, headers=headers)</span><br><span class="line">html = opener.open(req_ligin).read().decode(<span class="string">'utf-8'</span>)</span><br><span class="line">print(html)</span><br></pre></td></tr></table></figure>
<h2 id="代理">代理</h2>
<p>有一种反爬虫策略就是对IP进行封锁。所以我们有时需要设置代理。</p>
<p>原理：代理服务器原理如下图，利用代理服务器可以很好处理IP限制问题。</p>
<p><img src="http://upload-images.jianshu.io/upload_images/3471485-097f1343b6952165.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240"></p>
<p>一般都是利用互联网上提供的一些免费代理IP进行爬取，而这些免费IP的质量残次不齐，出错是在所难免的，所以在使用之前我们要对其进行有效性测试。另外，对开源IP池有兴趣的同学可以学习Github上的开源项目：<a href="https://github.com/qiyeboy/IPProxyPool" target="_blank" rel="noopener">IPProxyPool</a>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">use_proxy</span><span class="params">(url,proxy_addr,iHeaders,timeoutSec)</span>:</span></span><br><span class="line">  <span class="string">'''</span></span><br><span class="line"><span class="string">  功能：伪装成浏览器并使用代理IP防屏蔽</span></span><br><span class="line"><span class="string">  @url：目标URL</span></span><br><span class="line"><span class="string">  @proxy_addr：代理IP地址</span></span><br><span class="line"><span class="string">  @iHeaders：浏览器头信息</span></span><br><span class="line"><span class="string">  @timeoutSec：超时设置（单位：秒）</span></span><br><span class="line"><span class="string">  '''</span></span><br><span class="line">  proxy = urllib.request.ProxyHandler(&#123;<span class="string">"http"</span>:proxy_addr&#125;)</span><br><span class="line">  opener = urllib.request.build_opener(proxy,urllib.request.HTTPHandler)</span><br><span class="line">  urllib.request.install_opener(opener)</span><br><span class="line">  <span class="keyword">try</span>:</span><br><span class="line">      req = urllib.request.Request(url,headers = iHeaders)  <span class="comment">#伪装为浏览器并封装request</span></span><br><span class="line">      data = urllib.request.urlopen(req).read().decode(<span class="string">"utf-8"</span>,<span class="string">"ignore"</span>)  </span><br><span class="line">  <span class="keyword">except</span> Exception <span class="keyword">as</span> er:</span><br><span class="line">      print(<span class="string">"爬取时发生错误，具体如下："</span>)</span><br><span class="line">      print(er)</span><br><span class="line">  <span class="keyword">return</span> data    </span><br><span class="line">url = <span class="string">"http://www.baidu.com"</span></span><br><span class="line">proxy_addr = <span class="string">"125.94.0.253:8080"</span></span><br><span class="line">iHeaders = &#123;<span class="string">"User-Agent"</span>:<span class="string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.22 Safari/537.36 SE 2.X MetaSr 1.0"</span>&#125;</span><br><span class="line">timeoutSec = <span class="number">10</span></span><br><span class="line">data = use_proxy(url,proxy_addr,iHeaders,timeoutSec)</span><br><span class="line">print(len(data))</span><br><span class="line"></span><br><span class="line">作者：whenif</span><br><span class="line">链接：http://www.jianshu.com/p/<span class="number">0</span>bfd0c48457f</span><br><span class="line">來源：简书</span><br><span class="line">著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</span><br></pre></td></tr></table></figure>
<h1 id="后续">后续</h1>
<p>后面我会在考虑学习多线程异或多进程改写之前的爬虫，研究研究前面引用的文章里的提到的一些我之前还未了解的技术，感觉要学的东西还是很多，快要开学了，自己的效率有点低，也不知道还能有多少时间给自己这样浪。</p>

      
    </div>

    

    
    
    

    

    
       
    
    

    
      <div>
        



  



<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Lart Pang</li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    
    <a href="https://plart.pw/langs/python/spyder_end/" title="关于近期爬虫学习的总结">https://plart.pw/langs/python/spyder_end/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/python/" rel="tag"># python</a>
          
        </div>
      

      
      
        <div class="post-widgets">
        

        

        
          
          <div class="social_share">
            
            
               <div id="needsharebutton-postbottom">
                 <span class="btn">
                    <i class="fa fa-share-alt" aria-hidden="true"></i>
                 </span>
               </div>
            
          </div>
        
        </div>
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/langs/python/spyderforwordcloud/" rel="next" title="利用豆瓣短评数据生成词云">
                <i class="fa fa-chevron-left"></i> 利用豆瓣短评数据生成词云
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/life/麦兜饭宝奇兵/" rel="prev" title="麦兜，幸福的麦兜">
                麦兜，幸福的麦兜 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Lart Pang</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">58</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">6</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">30</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/lartpang" title="GitHub &rarr; https://github.com/lartpang" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:%6C%61%72%74%70%61%6E%67%40%31%36%33%2E%63%6F%6D" title="E-Mail &rarr; mailto:%6C%61%72%74%70%61%6E%67%40%31%36%33%2E%63%6F%6D" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://weibo.com/140jmx" title="Weibo &rarr; https://weibo.com/140jmx" rel="noopener" target="_blank"><i class="fa fa-fw fa-weibo"></i>Weibo</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#关于爬虫背后的这一节是主要是http的概要下一节是我的一些总结"><span class="nav-number">1.</span> <span class="nav-text">关于爬虫背后的（这一节是主要是http的概要，下一节是我的一些总结）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#http-协议"><span class="nav-number">1.1.</span> <span class="nav-text">HTTP 协议</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#一些术语"><span class="nav-number">1.1.1.</span> <span class="nav-text">一些术语</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#简单流程"><span class="nav-number">1.1.2.</span> <span class="nav-text">简单流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#http-消息http-message"><span class="nav-number">1.1.3.</span> <span class="nav-text">HTTP 消息（HTTP Message）</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#爬虫是一个综合性的工具"><span class="nav-number">2.</span> <span class="nav-text">爬虫是一个综合性的工具</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#获取url"><span class="nav-number">2.1.</span> <span class="nav-text">获取URL</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#获取页面及异常处理"><span class="nav-number">2.2.</span> <span class="nav-text">获取页面及异常处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#伪装浏览器"><span class="nav-number">2.3.</span> <span class="nav-text">伪装浏览器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#时间问题"><span class="nav-number">2.4.</span> <span class="nav-text">时间问题</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#超时重连"><span class="nav-number">2.4.1.</span> <span class="nav-text">超时重连</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#线程延迟"><span class="nav-number">2.4.2.</span> <span class="nav-text">线程延迟</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#页面解析"><span class="nav-number">2.5.</span> <span class="nav-text">页面解析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#正则匹配"><span class="nav-number">2.5.1.</span> <span class="nav-text">正则匹配</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#beautifulsoup4"><span class="nav-number">2.5.2.</span> <span class="nav-text">beautifulsoup4</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#文件读写"><span class="nav-number">2.6.</span> <span class="nav-text">文件读写</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#登录信息"><span class="nav-number">2.7.</span> <span class="nav-text">登录信息</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#代理"><span class="nav-number">2.8.</span> <span class="nav-text">代理</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#后续"><span class="nav-number">3.</span> <span class="nav-text">后续</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2017 – <span itemprop="copyrightYear">2018</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Lart Pang</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v6.5.0</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv" title="总访客量">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="site-pv" title="总访问量">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    
	
    

    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>












  













  



  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/reading_progress/reading_progress.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.5.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.5.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=6.5.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.5.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.5.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.5.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.5.0"></script>



  



  










  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  

  
  

  
  

  


  
  
  
  <script src="/lib/needsharebutton/needsharebutton.js"></script>

  <script>
    
      pbOptions = {};
      
          pbOptions.iconStyle = "box";
      
          pbOptions.boxForm = "horizontal";
      
          pbOptions.position = "bottomCenter";
      
          pbOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      
      new needShareButton('#needsharebutton-postbottom', pbOptions);
    
    
  </script>

  

  

  

  

  

  
  <style>
    .copy-btn {
      display: inline-block;
      padding: 6px 12px;
      font-size: 13px;
      font-weight: 700;
      line-height: 20px;
      color: #333;
      white-space: nowrap;
      vertical-align: middle;
      cursor: pointer;
      background-color: #eee;
      background-image: linear-gradient(#fcfcfc, #eee);
      border: 1px solid #d5d5d5;
      border-radius: 3px;
      user-select: none;
      outline: 0;
    }

    .highlight-wrap .copy-btn {
      transition: opacity .3s ease-in-out;
      opacity: 0;
      padding: 2px 6px;
      position: absolute;
      right: 4px;
      top: 8px;
    }

    .highlight-wrap:hover .copy-btn,
    .highlight-wrap .copy-btn:focus {
      opacity: 1
    }

    .highlight-wrap {
      position: relative;
    }
  </style>
  <script>
    $('.highlight').each(function (i, e) {
      var $wrap = $('<div>').addClass('highlight-wrap')
      $(e).after($wrap)
      $wrap.append($('<button>').addClass('copy-btn').append('复制').on('click', function (e) {
        var code = $(this).parent().find('.code').find('.line').map(function (i, e) {
          return $(e).text()
        }).toArray().join('\n')
        var ta = document.createElement('textarea')
        document.body.appendChild(ta)
        ta.style.position = 'absolute'
        ta.style.top = '0px'
        ta.style.left = '0px'
        ta.value = code
        ta.select()
        ta.focus()
        var result = document.execCommand('copy')
        document.body.removeChild(ta)
        
          if(result)$(this).text('复制成功')
          else $(this).text('复制失败')
        
        $(this).blur()
      })).on('mouseleave', function (e) {
        var $b = $(this).find('.copy-btn')
        setTimeout(function () {
          $b.text('复制')
        }, 300)
      }).append(e)
    })
  </script>


  

</body>
</html>

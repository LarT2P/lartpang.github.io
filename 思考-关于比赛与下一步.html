
<html lang="zh-cn">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type" />
<link href="tools/asserts/css/default.css" rel="stylesheet">
<link href="tools/asserts/css/html.css" rel="stylesheet"></link>
</head>
<body>
<h1 id="_1">比赛进度&amp;下一步的想法</h1>
<blockquote>
<p>By Lart, 2019-01-06</p>
</blockquote>
<div class="toc">
<ul>
<li><a href="#_1">比赛进度&amp;下一步的想法</a><ul>
<li><a href="#_2">关于比赛</a></li>
<li><a href="#_3">下一步的打算</a></li>
</ul>
</li>
</ul>
</div>
<p><img alt="From unsplash" src="https://images.unsplash.com/photo-1502679718843-1c1d20c1090b?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=1500&amp;q=80" /></p>
<h2 id="_2">关于比赛</h2>
<p>现在找到了一个18年的IJCAI的论文，实现了一个架构——R3Net，在ResNeXt的基础上外扩了一系列的循环残差式的结构，按照论文的描述，实现了当时的“state of the art”。</p>
<p>按照老师的说法，没有时间去尝试比较哪个网络架构更有效，直接尝试最优的就可以。确实如此，毕竟直接使用，起步就不一样，与其按照之前的，在DHSNet的基础上改动，倒不如直接使用最好的。</p>
<p>当时老师推荐的是@Tiantian Wang的一篇论文提出的架构——SRM，但是在我搜索这篇论文的时候，却找到了这个<a href="https://drive.google.com/file/d/1GavhYgp-4RlmO5IqAhtfcnDahy9FX3BZ/view?usp=drive_open">R3Net的PPT</a>，论文标题是《R3Net: Recurrent Residual Refinement Network for Saliency Detection》，之所以被吸引，主要是因为他题目让我想到了最近在思考的RNN，点进去一看，顿时发现了这个论文的给力之处。</p>
<p>最明显的感觉就是，快，就一个字。论文里在实验的时候，使用的就是6000次迭代，就花了80min，还是GTX1080Ti，这让我很惊讶，相比之下，DHSNet那个可就是龟速了。为了尝试一下，clone，注释，阅读，运行，确实快！基本上一晚上可以来三四次，很快。感觉主要的快速之处在于大量的残差结构的使用，尤其是作为backbone的ResNeXt，它的横向扩展的思路，使其参数量大大减少，又实现了足够的复杂结构，在速度与准确度上做到了一个较好的平衡。当然还有全卷积的结构，没有多余的全连接，也在一定程度上实现了加速，而且这里对于输入的数据并没有放缩操作，直接按照原大小进行的处理，这一点很棒，因为如果评测是外部的（非自己实现的），那么肯定默认是使用原图大小的输出来与真值评价，而我们之前使用的DHSNet，不论在训练还是测试的时候，都实现进行了对于数据的预处理，这个预处理里存在着固定大小的缩放。这一点对于未来的扩展不是很有利。相比之下，R3Net的实现就很科学了。</p>
<p>在阅读代码的时候，总体的感觉就是结构很清晰，代码很直观，对于架构的实现简单粗暴，反而使得阅读和修改更为方便，确实给力！而且作者<a href="https://zijundeng.github.io">@Zijun Deng</a>的<a href="https://github.com/zijundeng/pytorch-semantic-segmentation">另一个仓库</a>又是一个值得学习的实现，实现了很多的分割架构，顿时感觉这一下知道了好多的知识。这个作者确实厉害！</p>
<p>尝试了R3Net，在MSRA10K上进行了6000次迭代的训练，按照作者的论文的训练参数，只是batch_size由于当时操作环境所限，只能设定为2，实现了在ECSSD数据集上的0.90的Fm，达不到作者论文里的0.935的地步，初步认为是这个batch_size太小所致。</p>
<p>为了进一步的得到更好的成绩，我们打算利用caff2来实现对于pytorch模型的转化，在配合android来实现app的实现，这样会可以有更多的加分。但是这里又是一堆坑。外加上这个比赛的赛题有很多不合理的地方，给出的指标不适合于题目描述的“人像精细分割”的对应的matting任务，倒是有些像显著性检测的标准，给了F测度和mae两个指标，若是matting，这根本不合适，按照之前的一篇matting领域的重要的论文<a href="http://www.ims.tuwien.ac.at/publications/tuw-180666">《A Perceptually Motivated Online Benchmark for Image Matting》</a>给出的四个指标——SAE，MSE，连通误差，梯度误差，这才是更适合matting的评价的。所以矛盾存在，就导致我们选择架构就存在了犹豫。</p>
<p>多方考量后，还是如前描述，选择从显著性检测的架构入手，有可能再考虑matting细化的情况。</p>
<h2 id="_3">下一步的打算</h2>
<ol>
<li>暂先确定一个模型</li>
<li>**关键行尝试：<code>pytorch -&gt; app</code></li>
<li>寻找最好的模型</li>
<li>转换最好的模型</li>
</ol>
<p>pytorch真心适合搞学术研究，没有tensorflow那么多套路，那么复杂。同一个想法，实现不会差上太多，反而更是贴合python的精神，一个想法只有一种实现。但是论实际来讲，tensorflow的布局是真大，各种领域都要插上一脚，不论是工业还是学术，感觉都是它最初设计就在考虑的，这导致它自身在不同领域的转换应该是没有太大的成本的，而pytorch还需要借助FB的工业级产品caffe2来实现。</p>
<p>但是，pytorch自身的吸引力，已经足够了，其他都是点缀而已。</p>
</body>
</html>

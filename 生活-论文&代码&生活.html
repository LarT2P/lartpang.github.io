
<html lang="zh-cn">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type" />
<link href="tools/asserts/css/default.css" rel="stylesheet"></link>
<link href="tools/asserts/css/html.css" rel="stylesheet"></link>
</head>
<body>
<h1 id="_1">论文&amp;代码&amp;生活</h1>
<blockquote>
<p>By Lart, 2018-12-22</p>
</blockquote>
<div class="toc">
<ul>
<li><a href="#_1">论文&amp;代码&amp;生活</a><ul>
<li><a href="#_2">论文</a></li>
<li><a href="#_3">代码</a></li>
<li><a href="#_4">生活</a></li>
</ul>
</li>
</ul>
</div>
<p><img alt="upslash" src="https://images.unsplash.com/photo-1499028344343-cd173ffc68a9?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=750&amp;q=80" /></p>
<h2 id="_2">论文</h2>
<p>这些日子主要在看论文，忙着跟随学姐的脚步，尽快补充相关的知识，尽快踏上显著性检测的道路。在读了一些论文后，最大的感受就是，显著性检测使用深度网路的时候，感觉套路很直观。</p>
<blockquote>
<p>主要参考了这篇综述：<a href="https://github.com/lartpang/ML_markdown/blob/0562f11ccc8cedb2d9f69e9f74f6769b6cbc41dc/图像分割/A%202017%20Guide%20to%20Semantic%20Segmentation%20with%20Deep%20Learning.md">https://github.com/lartpang/ML_markdown/blob/0562f11ccc8cedb2d9f69e9f74f6769b6cbc41dc/图像分割/A%202017%20Guide%20to%20Semantic%20Segmentation%20with%20Deep%20Learning.md</a></p>
</blockquote>
<p>主要是遇到了两种类型的结构：</p>
<ol>
<li>第一种是由<em>U-Net</em> 开创的<strong>编码-解码式</strong>的对称型结构，例如SegNet，RefineNet等。这种结构，编码器通过池化层逐渐的减少空间维度, 然后解码器逐逐渐的恢复物体的详细信息和空间维度. 通常在编码器和解码器之间有转换关系, 方便解码器更好的恢复物体的详细信息。在这里跨层链接是常见的，因为要结合各种尺度的特征。</li>
<li>而另一种则是采用各种上采样手段的非对称式结构，主要是由<em>FCN</em>启发的一系列模型，例如DeepLab系列，PSPNet等。这种结构主要是通过后续的一系列“花式操作”，来对于之前卷积层获得的特征图进行进一步细化和融合，在这里主要的是一些比较特殊的卷积策略。例如DeepLab使用的空洞卷积，FCN使用的分数卷积（分数卷积也是一种转置卷积，它对应的是<em>步长不为1</em>的原始卷积过程）。<blockquote>
<p>具体结构动态图可见：<a href="https://github.com/vdumoulin/conv_arithmetic">https://github.com/vdumoulin/conv_arithmetic</a></p>
</blockquote>
</li>
</ol>
<p>还涉及到了一个比较经典的后处理操作：CRF，这个操作主要被用来基于周边像素来‘平滑’分割。它们的工作原理是相似的像素会趋向于分为同一个类别。</p>
<p>两者实际上都是使用了CNN的提取特征的强大能力，通过利用获得的多尺度的特征，进行了各种改进的后续融合处理。而对于类FCN结构，则是进一步对得到的最终的特征图进一步处理细化，没有太多的使用早期的卷积特征图。</p>
<p>这些论文，都会先使用一个用于分类的骨干网络（VGG、ResNet），得到压缩后的特征图，然后要在这个特征图的基础上进行尺寸恢复，这就需要考虑是用什么样的手段进行恢复。比较有意思的一个地方就是恢复分辨率的手段。这里在<a href="https://github.com/lartpang/ML_markdown/issues/25#issuecomment-448911117">issue里</a>总结了下：</p>
<ul>
<li>
<p>语义分割体系结构的另一个重要方面是使用学习好的deconvolutions对低分辨率分割图进行特征图上采样以获得输入图像分辨率的机制，或者在编码器中使用以计算为代价的扩张卷积来避免部分的分辨率下降。即使在现代GPU上，扩张卷积（Dilated convolutions ）也非常昂贵。</p>
<p>这篇关于<a href="http://link.zhihu.com/?target=http%3A//distill.pub/2016/deconv-checkerboard/">distill.pub</a>的文章解释了有关反卷积的更多细节。</p>
</li>
<li>
<p>不同网络如何实现上采样</p>
</li>
<li>
<p>FCN 双线性插值初始化(虽然还不理解), 分数卷积实现上采样</p>
</li>
<li>
<p>SegNet 使用对应的最大值索引进行恢复, 变成稀疏的特征图, 再利用后接的卷积实现进一步的密集化 [unpooling]</p>
<p>虽然这有助于保持高频信息的完整性，但是当从低分辨率特征图中unpooling时，它也会错过相邻的信息。</p>
</li>
<li>
<p>Deeplab 通过空洞卷积的组合来恢复全分辨率的特征映射，这种方法计算的特征映射更加密集，然后简单地对特征的响应进行<strong>双线性插值</strong>恢复到原始图像大小</p>
</li>
<li>
<p>U‐Net 2x2卷积外围补零, 实现的上采样</p>
<p>通过其跳过concatenation连接的架构允许每个阶段的解码器学习在编码器中池化时丢失的相关特征。</p>
</li>
<li>
<p>RefineNet 上采样是在Multi-resolution fusion单元完成的, 这里感觉更像是使用的双线性插值</p>
</li>
<li>
<p>PSPNet 双线性插值直接对低维特征映射进行上采样，以获得与原始特征图相同的大小特征, 最后，不同级别的特征被连接为最终的金字塔池化全局特征。</p>
<p><img alt="image" src="https://user-images.githubusercontent.com/16298490/50284453-04942780-0494-11e9-8084-8abb06cc5e25.png" /></p>
</li>
<li>
<p>Mask‐RCNN 不需要上采样, 因为它是基于Faster R-CNN的, 所有预测的结果都是针对于原始图像大小的.</p>
</li>
</ul>
<h2 id="_3">代码</h2>
<ul>
<li>准备数据</li>
<li>调整输入</li>
<li>搭建网络</li>
<li>设定损失</li>
<li>设定优化器</li>
<li>开始迭代训练</li>
<li>执行前向传播 <code>model.forward(inputs)</code></li>
<li>计算损失</li>
<li>损失反向传播 <code>loss.backward()</code></li>
<li>执行优化</li>
<li>保存模型</li>
<li>验证集上测试效果，获得指标 <code>F_measure, mae</code></li>
<li>存储最好的模型</li>
<li>直到迭代结束</li>
</ul>
<p>之前研究的是学姐给的代码，略微有些复杂，可能是为了兼容更多的骨干网络，导致整体复杂了些。但是看了<code>@guanwenlong</code>学长的<em>DHSNet</em> 的复现后，感觉挺直观的，可以参考着用。这个修改起来感觉会容易一些。</p>
<h2 id="_4">生活</h2>
<p>这些天看电脑都看的脑子疼，眼睛疼，真是蛋疼，感觉睡觉一直都睡得不踏实，昏昏的。</p>
<p>前些日子流星雨，也没看到过一个。</p>
<p>今日冬至，吃饺子，人是死啦多，又吃了灵芝米线，死啦贵。最讨厌这种所谓“名小吃”，不接地气，不实在。</p>
<p>个人对于吃饭还是有些想法的，有些东西不适合充饥，就比如米线，这个让我很容易想起来家乡那边的粉条，那个东西烩菜的时候加一些，很不错，但是单独吃，进了胃，总感觉滑滑的不踏实。不如米饭面条来得实在一些。</p>
<p><img alt="wechat" src="tools/asserts/img/qrcode_wechat.jpg" title="欢迎关注个人公众号: 码后闲语" /></p>
<p><a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="知识共享许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>进行许可.</p>
</body>
</html>

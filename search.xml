<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[生产与学术]]></title>
    <url>%2F%E7%94%9F%E6%B4%BB-%E7%94%9F%E4%BA%A7%E4%B8%8E%E5%AD%A6%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[生产与学术 upsplash 生产与学术, 真实的对立... 这是我这两天对pytorch深度学习-&gt;android实际使用的这个流程的一个切身感受. 这两天 最近在研究将pytorch的模型转换为独立的app, 网上寻找, 找到了一个流程: pytorch-&gt;onnx-&gt;caffe2-&gt;android apk. 主要是基于这篇文章的启发: caffe2&amp;pytorch之在移动端部署深度学习模型(全过程!). 这两天就在折腾这个工具链，为了导出onnx的模型, 不确定要基于怎样的网络, 是已经训练好的, 还是原始搭建网络后再训练来作为基础. 所以不断地翻阅pytorch和onnx的官方示例, 想要研究出来点什么, 可是, 都是自己手动搭建的模型. 而且使用的是预训练权重, 不是这样: 123456789101112131415161718192021222324def squeezenet1_1(pretrained=False, **kwargs): r"""SqueezeNet 1.1 model from the `official SqueezeNet repo &lt;https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1&gt;`_. SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters than SqueezeNet 1.0, without sacrificing accuracy. Args: pretrained (bool): If True, returns a model pre-trained on ImageNet """ model = SqueezeNet(version=1.1, **kwargs) if pretrained: model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_1'])) return model# Get pretrained squeezenet modeltorch_model = squeezenet1_1(True)from torch.autograd import Variablebatch_size = 1 # just a random number# Input to the modelx = Variable(torch.randn(batch_size, 3, 224, 224), requires_grad=True)# Export the modeltorch_out = torch.onnx._export(torch_model, # model being run x, # model input (or a tuple for multiple inputs) "squeezenet.onnx", # where to save the model (can be a file or file-like object) export_params=True) # store the trained parameter weights inside the model file 就是这样: 123456789# Create the super-resolution model by using the above model definition.torch_model = SuperResolutionNet(upscale_factor=3)# Load pretrained model weightsmodel_url = 'https://s3.amazonaws.com/pytorch/test_data/export/superres_epoch100-44c6958e.pth'batch_size = 1 # just a random number# Initialize model with the pretrained weightstorch_model.load_state_dict(model_zoo.load_url(model_url))# set the train mode to false since we will only run the forward pass.torch_model.train(False) 两种都在载入预训练权重, 直接加载到搭建好的网络上. 对于我手头有的已经训练好的模型, 似乎并不符合这样的条件. 导出整体模型 最后采用尽可能模仿上面的例子代码的策略, 将整个网络完整的导出(torch.save(model)), 然后再仿照上面那样, 将完整的网络加载(torch.load())到转换的代码中, 照猫画虎, 以进一步处理. 这里也很大程度上受到这里的启发: https://github.com/akirasosa/mobile-semantic-segmentation 本来想尝试使用之前找到的不论效果还是性能都很强的R3Net进行转换, 可是, 出于作者搭建网络使用的特殊手段, 加上pickle和onnx的限制, 这个尝试没有奏效, 只好转回头使用之前学习的DHS-Net的代码, 因为它的实现是基于VGG的, 里面的搭建的网络也是需要修改来符合onnx的要求, 主要是更改上采样操作为转置卷积(也就是分数步长卷积, 这里顺带温习了下pytorch里的nn.ConvTranspose2d()的计算方式), 因为pytorch的上采样在onnx转换过程中有很多的问题, 特别麻烦, 外加上修改最大池化的一个参数(nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=False)的参数ceil_mode改为ceil_mode=False, 这里参考自前面的知乎专栏的那篇文章), 这样终于可以转换了, 为了方便和快速的测试, 我只是训练了一个epoch, 就直接导出模型, 这次终于可以顺利的torch.save()了. 12filename_opti = ('%s/model-best.pth' % check_root_model)torch.save(model, filename_opti) 之后便利用类似的代码进行了书写. 12345678910IMG_SIZE = 224TMP_ONNX = 'cache/onnx/DHSNet.onnx'MODEL_PATH = 'cache/opti/total-opti-current.pth'# Convert to ONNX oncemodel = torch.load(MODEL_PATH).cuda()model.train(False)x = Variable(torch.randn(1, 3, 224, 224), requires_grad=True).cuda()torch_out = torch.onnx._export(model, x, TMP_ONNX, export_params=True) caffe2模型转换 载入模型后, 便可以开始转换了, 这里需要安装caffe2, 官方推荐直接conda安装pytorch1每夜版即可, 会自动安装好依赖. 说起来这个conda, 就让我又爱又恨, 用它装pytorch从这里可以看出来, 确实不错, 对系统自身的环境没有太多的破坏, 可是用它装tensorflow-gpu的时候, 却是要自动把conda源里的cuda, cudnn工具包都给带上, 有时候似乎会破坏掉系统自身装载的cuda环境(? 不太肯定, 反正现在我不这样装, 直接上pip装, 干净又快速). 之后的代码中, 主要的问题也就是tensor的cpu/cuda, 或者numpy的转换的问题了. 多尝试一下, 输出下类型就可以看到了. 12345# Let's also save the init_net and predict_net to a file that we will later use for running them on mobilewith open('./cache/model_mobile/init_net.pb', "wb") as fopen: fopen.write(init_net.SerializeToString())with open('./cache/model_mobile/predict_net.pb', "wb") as fopen: fopen.write(predict_net.SerializeToString()) 预处理的补充 这里记录下, 查看pytorch的tensor的形状使用tensor.size()方法, 查看numpy数组的形状则使用numpy数组的adarray.shape方法, 而对于PIL(from PIL import Image)读取的Image对象而言, 使用Image.size查看, 而且, 这里只会显示宽和高的长度, 而且Image的对象, 是三维, 在于pytorch的tensor转换的时候, 或者输入网络的时候, 要注意添加维度, 而且要调整通道位置(img = img.transpose(2, 0, 1)). 由于网络保存的部分中, 只涉及到了网络的结构内的部分, 对于数据的预处理的部分并不涉及, 所以说要想真正的利用网络, 还得调整真实的输入, 来作为更适合网络的数据输入. 要注意, 这里针对导出的模型的相关测试, 程实际上是按照测试网络的流程来的. 123456789# load the resized image and convert it to Ybr formatmean = np.array([0.485, 0.456, 0.406])std = np.array([0.229, 0.224, 0.225])img = Image.open("./data/ILSVRC2012_test_00000004_224x224.jpg")img = np.array(img)img = img.astype(np.float64) / 255img -= meanimg /= stdimg = img.transpose(2, 0, 1) 安卓的尝试 首先安卓环境的配置就折腾了好久, 一堆破事, 真实的生产开发, 真心不易啊... 这里最终还是失败了, 因为对于安卓的代码是在是不熟悉, 最起码的基础认知都不足, 只有这先前学习Java的一点皮毛知识, 根本不足以二次开发. 也就跑了跑几个完整的demo而已. AiCamera 这个跑通了, 但是这是个分类网络的例子, 对于我们要做的分割的任务而言, 有很多细节不一样. 输入有差异: 比赛要求的是若是提交apk, 那么要求可以从相册读取图片, 而例子是从摄像头读取的视频数据流. 虽然也处理的是视频帧, 但是要我们再次补充的内容又多了起来, 还是那句话, android一窍不通. 输出有差异: 自我猜测, 比赛为了测评, 输出必然也要输出到相册里, 不然何来测评一说? AICamera-Style-Transfer 这个例子我们参考了一下, 只是因为它的任务是对摄像头视频流数据风格迁移, 而且会直接回显到手机屏幕上, 这里我们主要是想初步实现对于我们网络模型安卓迁移的测试, 在第一个例子的基础上能否实现初步的摄像头视频流的分割, 然后下一步再进一步满足比赛要求. 可是, 尝试失败了. 虽然AS打包成了APK, 手机也安装上了, 可是莫名的, 在&quot;loading...&quot;中便闪退了... JejuNet 这个例子很给力, 但是使用的是tensorflowlite, 虽然可以用, 能够实现下面的效果, 可是, 不会改. img 而且是量化网络, 准确率还是有待提升. 最后的思考 没经验 吃就吃在没经验的亏上了, 都是初次接触, 之前没怎么接触过安卓, 主要是安卓的开发对于电脑的配置要求太高了, 自己的笔记本根本不够玩的. 也就没有接触过了. 外加上之前的研究学习, 主要是在学术的环境下搞得, 和实际的生产还有很大的距离, 科研与生产的分离, 这对于深度学习这一实际上更偏重实践的领域来说, 有些时候是尤为致命的. 关键时刻下不去手, 这多么无奈, 科学技术无法转化为实实在在的生产力, 忽然有些如梦一般的缥缈. 当然, 最关键的还是, 没有仔细分析赛方的需求, 没有完全思考清楚, 直接就开干了, 这个鲁莽的毛病, 还是没有改掉, 浪费时间不说, 也无助于实际的进度. 赛方的说明含糊, 应该问清楚. 若是担心时间, 那更应该看清楚要求, 切莫随意下手. 比赛说明里只是说要提交一个打包好的应用, 把环境, 依赖什么都处理好, 但是不一定是安卓apk呀, 可以有很多的形式, 但是这也只是最后的一点额外的辅助而已, 重点是模型的性能和效率呢. 莫忘初心, 方得始终. 为什么我想到的是这句. 下一步 基本上就定了还是使用R3Net, 只能是进一步的细节修改了, 换换后面的循环结构了, 改改连接什么的. 我准备再开始看论文, 学姐的论文可以看看, 似乎提出了一种很不错的后处理的方法, 效果提升很明显, 需要研究下. pickle和onnx的限制 pytorch的torch.save(model)保存模型的时候, 模型架构的代码里不能使用一些特殊的构建形式, R3Net的ResNeXt结构就用了, 主要是一些lambda结构, 虽然不是太清楚, 但是一般的搭建手段都是可以的. onnx对于pytorch的支持的操作, 在我的转化中, 主要是最大池化和上采样的问题, 前者可以修改ceil_mode为False, 后者则建议修改为转置卷积, 避免不必要的麻烦. 可见&quot;导出整体模型&quot;小节的描述. 打包apk安装 这里主要是用release版本构建的apk. 未签名的apk在我的mi 8se(android 8.1)上不能安装, 会解析失败, 需要签名, AS的签名的生成也很简单, 和生成apk在同一级上, 有生成的选项.]]></content>
      <categories>
        <category>生活与思考</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>思考</tag>
        <tag>编程</tag>
        <tag>学术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[比赛进度&下一步的想法]]></title>
    <url>%2F%E6%80%9D%E8%80%83-%E5%85%B3%E4%BA%8E%E6%AF%94%E8%B5%9B%E4%B8%8E%E4%B8%8B%E4%B8%80%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[比赛进度&amp;下一步的想法 From unsplash 关于比赛 现在找到了一个18年的IJCAI的论文，实现了一个架构——R3Net，在ResNeXt的基础上外扩了一系列的循环残差式的结构，按照论文的描述，实现了当时的“state of the art”。 按照老师的说法，没有时间去尝试比较哪个网络架构更有效，直接尝试最优的就可以。确实如此，毕竟直接使用，起步就不一样，与其按照之前的，在DHSNet的基础上改动，倒不如直接使用最好的。 当时老师推荐的是@Tiantian Wang的一篇论文提出的架构——SRM，但是在我搜索这篇论文的时候，却找到了这个R3Net的PPT，论文标题是《R3Net: Recurrent Residual Refinement Network for Saliency Detection》，之所以被吸引，主要是因为他题目让我想到了最近在思考的RNN，点进去一看，顿时发现了这个论文的给力之处。 最明显的感觉就是，快，就一个字。论文里在实验的时候，使用的就是6000次迭代，就花了80min，还是GTX1080Ti，这让我很惊讶，相比之下，DHSNet那个可就是龟速了。为了尝试一下，clone，注释，阅读，运行，确实快！基本上一晚上可以来三四次，很快。感觉主要的快速之处在于大量的残差结构的使用，尤其是作为backbone的ResNeXt，它的横向扩展的思路，使其参数量大大减少，又实现了足够的复杂结构，在速度与准确度上做到了一个较好的平衡。当然还有全卷积的结构，没有多余的全连接，也在一定程度上实现了加速，而且这里对于输入的数据并没有放缩操作，直接按照原大小进行的处理，这一点很棒，因为如果评测是外部的（非自己实现的），那么肯定默认是使用原图大小的输出来与真值评价，而我们之前使用的DHSNet，不论在训练还是测试的时候，都实现进行了对于数据的预处理，这个预处理里存在着固定大小的缩放。这一点对于未来的扩展不是很有利。相比之下，R3Net的实现就很科学了。 在阅读代码的时候，总体的感觉就是结构很清晰，代码很直观，对于架构的实现简单粗暴，反而使得阅读和修改更为方便，确实给力！而且作者[@Zijun Deng](https://zijundeng.github.io)的另一个仓库又是一个值得学习的实现，实现了很多的分割架构，顿时感觉这一下知道了好多的知识。这个作者确实厉害！ 尝试了R3Net，在MSRA10K上进行了6000次迭代的训练，按照作者的论文的训练参数，只是batch_size由于当时操作环境所限，只能设定为2，实现了在ECSSD数据集上的0.90的Fm，达不到作者论文里的0.935的地步，初步认为是这个batch_size太小所致。 为了进一步的得到更好的成绩，我们打算利用caff2来实现对于pytorch模型的转化，在配合android来实现app的实现，这样会可以有更多的加分。但是这里又是一堆坑。外加上这个比赛的赛题有很多不合理的地方，给出的指标不适合于题目描述的“人像精细分割”的对应的matting任务，倒是有些像显著性检测的标准，给了F测度和mae两个指标，若是matting，这根本不合适，按照之前的一篇matting领域的重要的论文《A Perceptually Motivated Online Benchmark for Image Matting》给出的四个指标——SAE，MSE，连通误差，梯度误差，这才是更适合matting的评价的。所以矛盾存在，就导致我们选择架构就存在了犹豫。 多方考量后，还是如前描述，选择从显著性检测的架构入手，有可能再考虑matting细化的情况。 下一步的打算 暂先确定一个模型 **关键行尝试：pytorch -&gt; app 寻找最好的模型 转换最好的模型 pytorch真心适合搞学术研究，没有tensorflow那么多套路，那么复杂。同一个想法，实现不会差上太多，反而更是贴合python的精神，一个想法只有一种实现。但是论实际来讲，tensorflow的布局是真大，各种领域都要插上一脚，不论是工业还是学术，感觉都是它最初设计就在考虑的，这导致它自身在不同领域的转换应该是没有太大的成本的，而pytorch还需要借助FB的工业级产品caffe2来实现。 但是，pytorch自身的吸引力，已经足够了，其他都是点缀而已。]]></content>
      <categories>
        <category>生活与思考</category>
      </categories>
      <tags>
        <tag>比赛</tag>
        <tag>进度</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[努力与情绪]]></title>
    <url>%2F%E6%80%9D%E8%80%83-%E5%8A%AA%E5%8A%9B%E4%B8%8E%E6%83%85%E7%BB%AA%2F</url>
    <content type="text"><![CDATA[努力与情绪 迷惘 情绪 这段时间过得很压抑，自我的提升，现实的需求，理想的渴求，以及实际的压抑与焦虑，不安与混乱互相混杂，搅成一团。 比赛与matting 老师要我们做 oppo 的一个比赛，人像分割的任务，zengyu学姐给安排了一些显著性的论文让我们看，这之后老师又安排我收集总结数据集。 也算是明确了方向，这个比赛实际上是 matting 的问题。开始还不是很理解这个任务，只是简单的认识到，也就是所谓的“抠图”任务。在收集数据集的过程中，发现这个任务更是小众，每年的出名的论文也不多，一搜就能搜出来的也就是 adobe 的一篇和港中文的两篇，以及阿里的一片最新的论文。 这个任务里，最严重的问题是数据集的缺少，这个领域的论文好多都是在提出方法的同时，都要自己制作一个数据集。这里面最大的问题是，这个任务在早期，还不是深度学习方法泛滥的时期，问题还不大，但是到了后期，开始使用深度学习来处理这个问题的时候，数据集的问题就被放大了，直到adobe这一篇出来的时候，才出现了一个较为精细的量也较大一点的数据集，可是不公开，要和作者要。而港中文也出了两篇文章，也是做人像matting的，也算是公开了一个自己的数据集，目前而言只能在这个基础上进行训练了。但是当前也有一个很大的数据集，但是并不是很精细，也开放了下载，(@supervise.ly)，目前在下载，不知道会如何。 实验 很压抑，想起了之前的数字图像处理的实验，眼看就要验收了，可是最后有些东西没有满足要求，最后还是放弃了，明天，哦不，今天下午就要最后验收了，拖了这么久，希望一切顺利啊。又想起了之前SOPC实验，真烦人，还得修改报告，最后才能算结束。 这里还是态度问题呀，唉。原本就没有认真完成这最后的要求。 努力 不知道研究生的日子会怎么度过，感觉会很有压力，但是想想，如果不能发论文的话，那岂不更是一件悲伤的事情？ 最难过的事，莫过于看着别人似有所成，而自己却一事无成。 在目前的matting的进度上，就似乎有这样的问题，@Z, 他主要看代码，进展很快，目前已经小有成效，而我阅读论文，虽然看了不少，但是却还没有关注过实现，实践上有些差上了，看着他在忙碌，而自己却还未动手，再想想四号就要开组会，有些小慌张，还得准备自己的汇报PPT啊，也不知道要汇报哪些内容。 努力是一件烧脑的事情啊，找不准方向就得空耗时间，空费精力。 但找准方向，又是多么的难。]]></content>
      <categories>
        <category>生活与思考</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>情绪</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文&代码&生活]]></title>
    <url>%2F%E7%94%9F%E6%B4%BB-2018%E5%B9%B412%E6%9C%8821%E6%97%A5%2F</url>
    <content type="text"><![CDATA[论文&amp;代码&amp;生活 upslash 论文 这些日子主要在看论文，忙着跟随学姐的脚步，尽快补充相关的知识，尽快踏上显著性检测的道路。在读了一些论文后，最大的感受就是，显著性检测使用深度网路的时候，感觉套路很直观。 主要参考了这篇综述：https://github.com/lartpang/ML_markdown/blob/0562f11ccc8cedb2d9f69e9f74f6769b6cbc41dc/图像分割/A%202017%20Guide%20to%20Semantic%20Segmentation%20with%20Deep%20Learning.md 主要是遇到了两种类型的结构： 第一种是由U-Net 开创的编码-解码式的对称型结构，例如SegNet，RefineNet等。这种结构，编码器通过池化层逐渐的减少空间维度, 然后解码器逐逐渐的恢复物体的详细信息和空间维度. 通常在编码器和解码器之间有转换关系, 方便解码器更好的恢复物体的详细信息。在这里跨层链接是常见的，因为要结合各种尺度的特征。 而另一种则是采用各种上采样手段的非对称式结构，主要是由FCN启发的一系列模型，例如DeepLab系列，PSPNet等。这种结构主要是通过后续的一系列“花式操作”，来对于之前卷积层获得的特征图进行进一步细化和融合，在这里主要的是一些比较特殊的卷积策略。例如DeepLab使用的空洞卷积，FCN使用的分数卷积（分数卷积也是一种转置卷积，它对应的是步长不为1的原始卷积过程）。 &gt; 具体结构动态图可见：https://github.com/vdumoulin/conv_arithmetic 还涉及到了一个比较经典的后处理操作：CRF，这个操作主要被用来基于周边像素来‘平滑’分割。它们的工作原理是相似的像素会趋向于分为同一个类别。 两者实际上都是使用了CNN的提取特征的强大能力，通过利用获得的多尺度的特征，进行了各种改进的后续融合处理。而对于类FCN结构，则是进一步对得到的最终的特征图进一步处理细化，没有太多的使用早期的卷积特征图。 这些论文，都会先使用一个用于分类的骨干网络（VGG、ResNet），得到压缩后的特征图，然后要在这个特征图的基础上进行尺寸恢复，这就需要考虑是用什么样的手段进行恢复。比较有意思的一个地方就是恢复分辨率的手段。这里在issue里总结了下： 语义分割体系结构的另一个重要方面是使用学习好的deconvolutions对低分辨率分割图进行特征图上采样以获得输入图像分辨率的机制，或者在编码器中使用以计算为代价的扩张卷积来避免部分的分辨率下降。即使在现代GPU上，扩张卷积（Dilated convolutions ）也非常昂贵。 这篇关于distill.pub的文章解释了有关反卷积的更多细节。 不同网络如何实现上采样 FCN 双线性插值初始化(虽然还不理解), 分数卷积实现上采样 SegNet 使用对应的最大值索引进行恢复, 变成稀疏的特征图, 再利用后接的卷积实现进一步的密集化 [unpooling] 虽然这有助于保持高频信息的完整性，但是当从低分辨率特征图中unpooling时，它也会错过相邻的信息。 Deeplab 通过空洞卷积的组合来恢复全分辨率的特征映射，这种方法计算的特征映射更加密集，然后简单地对特征的响应进行双线性插值恢复到原始图像大小 U‐Net 2x2卷积外围补零, 实现的上采样 通过其跳过concatenation连接的架构允许每个阶段的解码器学习在编码器中池化时丢失的相关特征。 RefineNet 上采样是在Multi-resolution fusion单元完成的, 这里感觉更像是使用的双线性插值 PSPNet 双线性插值直接对低维特征映射进行上采样，以获得与原始特征图相同的大小特征, 最后，不同级别的特征被连接为最终的金字塔池化全局特征。 image Mask‐RCNN 不需要上采样, 因为它是基于Faster R-CNN的, 所有预测的结果都是针对于原始图像大小的. 代码 准备数据 调整输入 搭建网络 设定损失 设定优化器 开始迭代训练 执行前向传播 model.forward(inputs) 计算损失 损失反向传播 loss.backward() 执行优化 保存模型 验证集上测试效果，获得指标 F_measure, mae 存储最好的模型 直到迭代结束 之前研究的是学姐给的代码，略微有些复杂，可能是为了兼容更多的骨干网络，导致整体复杂了些。但是看了@guanwenlong学长的DHSNet 的复现后，感觉挺直观的，可以参考着用。这个修改起来感觉会容易一些。 生活 这些天看电脑都看的脑子疼，眼睛疼，真是蛋疼，感觉睡觉一直都睡得不踏实，昏昏的。 前些日子流星雨，也没看到过一个。 今日冬至，吃饺子，人是死啦多，又吃了灵芝米线，死啦贵。最讨厌这种所谓“名小吃”，不接地气，不实在。 个人对于吃饭还是有些想法的，有些东西不适合充饥，就比如米线，这个让我很容易想起来家乡那边的粉条，那个东西烩菜的时候加一些，很不错，但是单独吃，进了胃，总感觉滑滑的不踏实。不如米饭面条来得实在一些。]]></content>
      <categories>
        <category>生活与思考</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[雪&毕设&代码]]></title>
    <url>%2F%E7%94%9F%E6%B4%BB-2018%E5%B9%B412%E6%9C%886%E6%97%A5%2F</url>
    <content type="text"><![CDATA[雪&amp;毕设&amp;代码 恍惚 雪 今天迎来了二零一八年的第一场雪，比平常来的更晚了一些。寒意也随之到来了，弄得我终于换下了穿了许久的单衣。 大连的寒风，真是叫人瑟瑟发抖哦。 毕设 学校开始定毕设的题目了，我的题目老师给大体确定了下，题目有些宽泛，属于“xx模型研究”类的题目，老师想的是希望我们可以打好扎实的编程基础，可以掌握主流框架的使用。 老师今天把几篇参考论文发了过来，看了下，涉及到一个新的任务，“sence labeling”，这个是要把图片中的所有成分都要划分出来，不同于语义分割的分割目标的要求，较之更为复杂一点。 当我网上搜索的时候，发现LeCun大神竟然有篇相关的文章，顿时一喜，但是又看了看老师给的那篇文章，是今年的文章，有代码的几率很低呀，我都在想，要不要考虑和作者要下代码？暂时先等等看，看看文章，话说，老师催的也是关于编程能力的积累，而不是这个毕设的任务，毕设开始还在明年呢，不用太着急，但是也不能完全放置，应该细细准备下，代码能力，相关资料，都得做好准备。 话说，六级考试又要到了，可是，准备了什么呢？匆匆缴费，却并未有所准备，英语一事，感觉自己已经没有了当初的动力，只能听之任之，尽量安心。话说这个追求也是基于一些功利了，因为据说六级分数较高的话，可以不用参加研究生的英语课。现在已经很讨厌英语课了，真不知道，会有怎样的感觉。 无法想象。 代码 tensorflow真是一个繁杂牛逼的框架，但是学习起来可也真是无从下手啊。 在网上找到了一个“cifar10-tensorflow”的代码仓库，代码结构很棒，准备在它的基础上进行学习。 准备先进行代码的整理，尽可能整理到一个文件中，压缩结构，也方便对于整体进行再次学习与复现。先考虑从简单的vgg11入手，今天实现了接近（还是相差百分之一左右）于这个代码作者的实现的准确率。可是却不知道后续要怎么调整了。 只好先从代码的角度入手了，仿照着实现了ResNet的结构，这里有个小的失误，一开始的实现是按照ImageNet的针对的结构实现的，这就怪自己没有细看论文了。针对cifar10数据集，ResNet网络在结构上进行了精简，主要变成了6n的结构，2n+1-&gt;2n-&gt;2n，主要是因为cifar10的数据大小所限。改了一晚上，倒也终于跑了起来，不知道最后的结果如何。希望可以好一些。 vgg11代码基本上是原本的代码，resnet20这里有了些自己的思考，但是一些关键处的处理，还是仿照着原本的代码写的，下一步就是在实现一下其他的，逐渐增多属于自己的部分的代码量，渐渐地，到最后，希望的是可以能把那个最重要的Solver类自己写出来。 写代码还是很有意思的，哈哈。 写在结束 天气越来越冷了，希望自己不会生病，生病一次就太麻烦了。 健健康康，顺顺利利，开开心心，这也就是我的2018最大的年末心愿了。]]></content>
      <categories>
        <category>记录与总结</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文&手写报告&胜者即正义]]></title>
    <url>%2F%E7%94%9F%E6%B4%BB-2018%E5%B9%B412%E6%9C%882%E6%97%A5%2F</url>
    <content type="text"><![CDATA[论文&amp;手写报告&amp;胜者即正义 加油 早上九点多才起床，天阴下雨，阴阴沉沉，睡意更显浓厚。在被窝里又挣扎了许久。稍微放松了下，才下了床。 迟起的早晨也注定了这一天整体的偏移。 上午看了看RFCN的论文，因为昨天看了这篇论文之后的一篇文章，讲述可变形卷积，因为是一个作者，所以在可变形卷积中提到了对于RFCN的一个改进，因为自己对于其中的可变形位置敏感RoI池化的设定不太了解，没想到在搜索的时候，搜索到了讲解RFCN的文章，对于位置敏感RoI池化介绍的很详细，阅读的很畅快。没想到，博客也可以这么写，写得好棒。忽然一下子感觉到了，好的文章分享是应该这样的，详细详细，关键之处要详细到小白文，无关之处要简略带过，没必要多谈，只针对最有疑惑的地方进行详细介绍。不过，对于目前的学习的过程来看，想要做到这样最大的问题就是不能很好地做到“舍得”，搞不清文章的重点与难点，虽然疑惑的地方有很多，但是关键的地方不好区分出来。还是需要阅读与思考。还是需要一定的积累的。 中午自己一个人吃了饭，又看了一个小时的小说。才决定睡觉。这一睡，又是一个多小时。雨还是淅淅沥沥，没个完。起床后洗了个澡，之后便开始了持续到晚上的报告时光，报告，手写，真有创意哈。 没有丝毫的意义。笔下的文字和脑中的想法根本不是一条线上的。写的手疼不想多谈。 今天发现了一部剧，《胜者即是正义》，口碑很好的一部日剧，新垣结衣呀！一部讲“套路”的律政剧。由此也认识到了这个鬼畜的男人——堺（jie）雅人。这剧漫画性比较强，但是对于日剧而言，这却也算一种风格，但这轻浮的表面之下，确实更为现实和实际的作为律师的根本准则——只对当事人负责，判断真实与否交给法律，而自己只是要保护当事人。这才是正义的基础，正义的判定应该交给法律，而非律师，抑或警察、检察官或者某个人自己的想法。各司其职，各尽其能，自己做好自己的事，或许才能开始谈论正义吧！ 话说，新垣结衣，笑起来好美呀！ 新垣结衣]]></content>
      <categories>
        <category>生活与思考</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学会学习-2]]></title>
    <url>%2F%E8%AF%BE%E7%A8%8B-Learning%20How%20to%20Learn-2%2F</url>
    <content type="text"><![CDATA[组块 组块化是一种思维的跃进，根据意义将信息碎片拼接起来，而新的逻辑整体让组块更容易记忆，同时也可以让你更轻松地将组块整合到所学内容的大框架内。 从神经科学的角度说，组块就是通过使用或意义连接在一起的信息碎片。通过集中注意力从而将大脑的不同部分连接起来，并将不同的想法联系在一起，是专注模式下学习的重要部分。 在紧张的时候，你的注意力会失去一些连接能力，这也是在你生气、紧张、害怕的时候，大脑似乎不能正常工作的原因所在。 事实上，在某个学术领域获得专业知识的第一步都是创建出概念组块。专业的培养是一小步一小步的，这个过程中小的组块可以形成更大的组块，而且随着你对学习材料的理解越来越深入，所有的专业知识都只是更有创造性的见解的铺路石。组块化可以让大脑工作得更有效。一旦你把某个想法、概念或动作组块化后，你就不再需要记住和这个想法、概念或动作有关的全部细节，你只需要知道最主要的那个概念就行了，也就是只需要记住组块。 建立 由小到大，先建立小的组块，再将小的组合成大的，之后再将这些大组块组合成更复杂更大型的组块，你随时都可以使用它们。 对于我们建立新的知识体系，示范性的例子则能在起步时帮助理解。但是在关注这些栗子的时候，一个顾虑是我们会过于关注某一个单独的步骤，而忽略步骤之间的联系，也就是说我们忽略了“为什么接下来就该进行到这个步骤”这个问题。所以说，我们要时刻保持一种陌生的状态，不能一味地去重复，要关注周围的变化，不能陷入脱离自我的状态，要时刻记得自己的目的是要学习过程方法，而非重复解决问题。 对于组块的建立，首先我们要专注于想要组块化的信息，其次呢，要求对之有基本的了解。再者就是需要有一定的背景知识。最终，练习也是极其重要的。 理解就像是强力胶，将潜在的记忆痕迹粘合在一起，它可以建立起一大圈记忆痕迹，并和其他痕迹链接起来。没有理解而建立的组块是无法利用的。 获取背景知识，这样你就不仅知道如何使用组块，还明白应该什么时候用它，能帮你认识新建立的组块是如何融入整体框架的。背景认识意味着学会在特定的时候使用正确的方法。 当然，还有在学习中，早期先掌握一个关键的框架（图片，小标题...），明白课程的层次结构，对于我们弄清楚应在哪里建立组块，以及如何把不同组块联系起来，是有帮助的。 回顾与自测 你才是解决问题和掌握概念的主体。 及时的自我检测是有价值的。能够帮你检验那些你以为已经明白了的问题，并且能够加快你的学习速度，当你能独自完成某件事时，你才是真正掌握了它。只是在看，或者就算理解了如何去做，也不代表你能真正做到，只有在你自己实际操作和完全掌握的情况下才能建立起神经模型。这时我们所发现的错误对于我们是极其重要的。 仅仅是扫一眼答案就以为你真的理解了，是一种学习中最为常见的自欺欺人式错觉，你需要让这些知识在你脑海里生根发芽。 当然可以提到的也有做标记。做笔记时高亮和下划线必须要谨慎，否则不仅没有效果还容易产生误导。试着在勾画前找到中心思想，并试着尽量减少划线和高亮的内容，每段不超过一句。另一方面，在空白处写笔记总结关键概念是一种很好的办法。 在我们的学习中，回顾往往很重要，有时要比反复阅读更有效。回顾知识时，我们并非机械地复述，而是在通过回顾这个过程加深理解，这也有助于我们形成知识组块。单纯回忆，脱离书本努力想起关键点，是促进组块化的最佳方式之一。 只有隔上一定时间后再重读才会有效果，因为这样，重读就更像是间隔重复练习。看书比回顾做起来简单，但学生会陷入 (一种自欺欺人的) 错觉，这种学习方式效率很低。在学习资料上花太多时间并不能保证你真的懂了，自测是一种极其有用的办法。 另一个小贴士：在常规学习场所以外回顾材料，会帮助你加深对材料的理解。当你学习新事物的时候 你通常会把最开始接触材料的地方，当作潜意识中的提示，但一到考试就乱了阵脚，因为考试与学习场所通常不同，通过在不同物理环境下回顾和思考学习资料，你会脱离对给定场所的依赖，这会帮助你避免由于考试与学习场所的不同而产生的问题。 同样的，在根基还没打牢就开始空建框架联系，例如进行思维导图，或者概念关联等等，实属徒劳无功。 影响实质 乙酰胆碱能让神经元与负责专注学习的大脑皮层间形成神经递质性的联系。当你注意力高度集中的时候，这些乙酰胆碱神经元就会广泛地投射出来，并且激活环路来控制突触可塑性 从而形成新的长期记忆，神经递质也对你的无意识有着深远的影响。 多巴胺的特殊的化学物质控制着我们的动力。这些多巴胺神经元是一个控制报酬性学习的大型脑部系统的一部分。当接受到一个毫无预期的奖励时，这些神经元将分泌出多巴胺，多巴胺的信号将广泛投射，这会对学习产生强有力的影响。同时也会影响决策，甚至是感官输入的价值所在。多巴胺参与预测未来奖励，它可以激励你做一些现在可能得不到奖励，但在将来会有一个更好的奖励的事情。 &gt; 缺少多巴胺神经元会导致动力缺乏，这就是我们俗称的快感缺乏，它会让你对那些曾经令你感到快乐的事物失去感兴趣。严重的多巴胺神经元缺乏会导致静止性震颤，迟缓、僵硬。这些症状就被称为帕金森氏病，最终它会导致紧张症，一种完全缺乏行动的病症。 血清素的水平也与风险行为有着紧密的联系。 情绪也可以强烈地影响你的学习 。 &gt; 杏仁核是认知和情绪进行有效结合的主要中心之一，是大脑边缘系统的一部分,它与海马体共同参与记忆和决策的进行过程。 知识迁移 首先，我们需要不断地增加我们的组块，组块式心理图书馆越大，运用越熟练，无论你学什么科目。你都将能够更轻易地解决问题，找到解决方法。 这有助于我们理解新概念，相似组块的联系，也就是迁移学习的基础。随着组块的增加，我们可以建立更大的组块，如果你将一系列的概念和解决方法吸纳为组块形式，你可以将它们看成是一簇神经模式。当你试图理清头绪时，如果你有一组结构良好的组块，你可以更容易地找到正确的解决方法。但如果你不训练变大的组块，它们就会保持模糊的状态，把你要学习的东西拼到一起就会更为困难。 建立组块式图书馆，就是在训练你的大脑，不仅要认出一个特定的概念，还要认出概念的类别，以便你能够自如地知晓，如何快速解决或处理你遇到的问题，你将开始看到一些为你简化解决方法的模式，并很快发现不同的解决手法，就潜藏在你的记忆边缘。 有两种途径理清头绪或解决问题：一是顺序性地一步步推理，二是通过整体性的直觉，顺序性思维涉及到专注模式，它的每一小步都有意地导向一个解决方法；另一方面，直觉通常似乎需要创造性的发散模式，来联系几个看上去在专注模式下不同的想法。 大多数较难的问题和概念都是通过直觉来理解的，因为新的想法和你熟悉的领域相去甚远。记住，发散模式是半随机地进行连接，这意味着它们带来的解决方法，应该由专注模式进行小心验证，直觉性的理解不是永远正确的。专注于你正在学习的单元，你会发现一旦你把第一个问题或概念放进心理图书馆，不论那是什么，第二个概念的进入就会容易一些，然后第三个概念也就更容易，这并不都那么简单，但会越来越容易。 过度识记 过度识记是有意义的，它能帮助使得行为自动化。自动性，(Automaticity)，确实很有用，但要警惕在单一学习阶段的重复性过度识记，研究表明，这可能是对宝贵的学习时间造成浪费，事实上，一旦你在某一阶段学会了一个基本概念，在这段时间不断地巩固它，并不能加强你所期许的长期记忆联系，重复你已经掌握的东西非常容易，但这可能会造成能力错觉，让你误以为自己已掌握了所有材料，而其实你只掌握了简单的部分，所以，你应该均衡学习，把精力集中在你认为困难的部分。 刻意训练 专注于学习的困难部分称为刻意训练，(deliberate，practice)。 在学习和生活中，理解如何得到真正的解决方法很重要，掌握一门新学科不仅要学习基础组块，更要学会如何选择和应用不同的组块，最佳的学习方法是练习如何在，需要不同技术和策略的问题以及情形中来回转换，这就是所谓的交替学习，当你掌握了某一技巧的基本概念，就好像在辅助轮的帮助下学会骑车时，你该开始交替练习，交叉于不同类别的问题、方法、概念和过程间，有时这么做会有点困难，。 例如在科学和数学上，提前看章末不同类型的习题，对于学习可能会有帮助，或者你可以偶尔探索，为什么一道题要用这种解法而不用别的，你需要让自己的大脑习惯这种思想，即仅仅知道如何使用特定的概念、方法或解题技巧是不够的，你也需要知道何时去使用，要贯彻交替学习的思想。 交替学习 这样有时可能会让你感到学习变得更困难了，但事实上它能帮助你学习得更深入，交替学习非常重要，尽管练习和重复，对帮助建立稳固的神经模式很重要，但却是交替学习能让大脑更具灵活性和创造性，这样你才能脱离仅会练习和重复，而开始学会独立思考。 当你在一个学科内交替学习，你开始在这个学科内发展创造力，当你在多个不同学科间交替学习，你能更容易地在不同领域的组块间创造联系，这能进一步提高你的创造性，当然，在不同领域间发展固定知识组块需要时间，所以有时需要取舍，成为几个领域的专家，意味着，你可以将一个领域的新思想引入另一个领域，但这也可能意味着，你在某个领域的专业知识，并不如专攻一个领域的人那么深厚，另一方面，如果你只专研一个学科，你可能对它有很深刻的理解，但也变得只习惯某种思考方式，这种根深蒂固的思考模式，让你很难把握新思想。而前者，则更具有创造力，更有可能出现改变。]]></content>
      <categories>
        <category>记录与总结</category>
      </categories>
      <tags>
        <tag>学习</tag>
        <tag>课程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学会学习-1]]></title>
    <url>%2F%E8%AF%BE%E7%A8%8B-Learning%20How%20to%20Learn-1%2F</url>
    <content type="text"><![CDATA[学习模式：专注模式和发散模式 两种模式不会同时存在，我们学习时通常是两种模式在不断地切换。这种随时能转换的能力，对于我们的学习，尤其是接触一些新的较难的东西时，尤为重要。学习困难的东西需要相当的时间，因为你的大脑需要转变它的学习方式以此来努力面对和消化新的事物。 专注模式下，我们的思维活动范围会局限在一个小部分，这通常是我们已经熟知的知识部分、思维模式，而这些面对未知的新知识的时候，往往就不够处理了，就会成为思维的局限，也就是惯性思维的束缚。这时我们就需要发散模式上场了。 发散模式下，我们的思维没有了束缚，会更加发散的活动，这也就导致我们的思维活动，往往会出现一些意料之外的惊喜。新的观点，新的角度，这些似乎隐藏在你的大脑的边缘地带的知识，思维方式被勾连起来。 影响大脑运作的因素 思考过程 记忆 情绪 动机 克服拖延症 当你看到一件你极度不情愿做的事情时，就好像是你激活了大脑中与疼痛相关的区域，你的大脑就会自然而然地去寻找停止这种负面刺激的方式，而这一方式便是将你的注意力转移到其他事情上。这也就是拖延症的关键所在。 但是我们真正去做的时候，这种不适很快就会消失。这也就是更为直接的解决拖延症的方法。 练习 所谓熟能生巧就是如此。适当的练习，会帮助我们加强记忆以及对于知识的熟悉程度。 比较合适的练习策略是间隔重复，具体做法是不断重复你尝试记忆的内容，但重复的过程必须间隔开来。就像是砌墙的过程一样，如果你不留足够的时间等灰浆变干，正如等待突触连接的形成与强化，你将无法获得好的记忆结构。 对于新的知识，实践出真知，同时最好有专家的指点，这样会让我们学习起来更为容易些。 劳逸结合 高强度的专注学习应该注意休息放松的重要性。适当的注意力的转移，表面的放松，会促使发散模式的工作，帮你完成对概念的理解，从某种意义上说，你的神经通路就可以像砂浆一样有个得到固化的机会。 强行的填鸭式有时并不能真正起到我们期望的作用。 即所谓劳逸结合。 这一方面，使用番茄工作法是值得借鉴的。定时的高强度学习，适度的休息奖励，互相促进。 睡眠 绝对地清醒会让你的大脑产生有毒的物质，而睡觉期间，大脑会进行排毒的工作，这件事有时候看起来像是浪费时间，实际上是大脑保持清洁和健康的一种方式。这些有毒物质会让你思维混乱，长时间的睡眠不足，更会让各种令人厌恶的情况发生，包括头疼、抑郁症、心脏类疾病、糖尿病，甚至寿命缩短，但是良好的睡眠不仅仅会帮你的大脑祛除有毒物质。实际上，它还是记忆力和学习过程中很重要的一部分。 在你睡觉的时候，它会清除掉一些记忆中不太重要的部分，同时增强你需要或想要记住的区域的记忆。在睡梦中，你的大脑也会，将你所努力学习到的东西，在神经中枢一遍遍排演以增强加深记忆力。研究表明，睡眠对人们区分找出困难问题的能力，和理解所学知识的能力有显著影响。当然，这一切的前提是，你必须通过做集中精力状态下的工作，在脑中搭建发散思维模型。 这实际上也算是一种发散模式与专注模式转换的情形。 如果你在打个小盹或者晚上睡觉之前，复习一遍所学东西的话 可以有更大可能性梦到它。如果你更进一步，告诉自己你想要梦到这些内容的话，可能你梦到它的几率也会大大提高，梦见你所学的知识，本质上能够增强你的理解能力。在一定程度上，它可以将你的记忆整合成更易被掌握的组块信息。 积极学习 在一场枯燥的讲座中保持注意力，可以考虑用提问来“伏击”演讲者，这种打断通常会带出更有趣的讨论。事实上，这符合一般准则，即比起被动的听讲，积极参与会让你学到更多。 运动和交流 慢跑或户外锻炼是让我的思维跳出常规想法的绝佳方法，而且这时极其可能迸发灵感，而且这时极其可能迸发灵感，这就像你的大脑进入了一个新模式。 同时，处于一个富有创造力的环境中，是一种提升自身创造力的方法。事实上，我认为同周围的人讨论自己的想法，对我的科研来说是极其重要的组成部分。]]></content>
      <categories>
        <category>记录与总结</category>
      </categories>
      <tags>
        <tag>学习</tag>
        <tag>课程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于态度的一段思考]]></title>
    <url>%2F%E6%80%9D%E8%80%83-%E5%85%B3%E4%BA%8E%E6%80%81%E5%BA%A6%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[最近经历了一些事情,有些小小的思考. 烦心 心思 最近做了两次实验,一次是计算机网络实验,一次是电子工程训练.让我有了更多的思考的是实验报告. 我还记得前三年里,也经历了很多的实验课,写过很多的实验报告,不管那门课如何的重要,抑或如何的不重要,都未曾有过一丝丝的轻视,仔细的构思每一个细节,完成每一个任务,一切都追求的是尽己所能.当然,结果都是好的,努力的付出是必然有回报的.在学校这个地方,还是很公平的,付出与收获大多数时候是成正比的. 记得大一大二时候做的物理实验,那段经历可以说是&quot;辉煌&quot;,分了两个学期,第一个学期的最终实验成绩据我所知,在我周围的同学里,我是最高的分数.当然,也与自己复习的到位有关系.后一个学期后劲不足,但是也还可以,将近九十的分数.也不算低了.每份报告,都是要求手写,回想起那一个个的夜晚/下午/上午的埋头计算/绘图/书写,绞尽脑汁,尽可能的&quot;提高&quot;数据的正确程度/合理程度,这份心思,虽然有些不太正确,但是却也极大地反映出了那个时候对于完美结果的追求. 后来还有一些上机的实验课,两次汇编实验,还有FPGA的实验,以及模拟电路实验,好多好多,我们专业,实验课不少,为了获得一个好的成绩,为了为现在的保研努一份力,多加一点机会,受了不少的煎熬,付出了不少的精力与心思.当时也想过,如果有机会,肯定不会在那样来一次,那种为了一次完美的报告,反复的修改打印,一丝一毫都不愿放过,一次次被我的强迫症逼得精疲力竭. 但是现在在我看来,当初的那种态度,却是现在的我极度需要的. 现在的生活,每天只要没课,早晨基本是九点起床,早餐也基本自行解决,喝包奶,吃点细碎的零食,若是有课,只能努力起床,瞌睡一上午;晚上基本都是十二点半睡觉,有时看个小说,就要拖到一点以后. 生活的习惯和心理上的放松时离不开的.毕竟,奋斗了三年,终于找到了出路,找到了下一站,再那么努力,总是会有些不愿意的.人就是一种懒惰的动物,惰性是本性,舒服的生活,会上瘾的. 回到学习上,如前面提到的,最近做了两次实验,实验做的一般,实验报告写的一般.计算机网络/电子工程训练,这两门课的报告,最主要的共同点,就是老师安排的很少,所以我就写的很少,内容很简陋. 所以,我就写的很少,内容很简陋... 在报告上操的心,放的心思少了,没有,也没想过要好好写.最终只能看着别人的优秀的结果,自我反思了. 报告给的模板里,并没有太多的内容,很简单,我写报告就是按着报告的模板来完成的,但是看着别人的充实的内容,我才意识到,目前自己的状态很不好.要是放在以前,估计是不会出现这样的问题的吧.以前只会多,不会少.现在只要写完,就会急匆匆的交上去,再也不想看一眼,而以前虽然也会有这样的感受,可是却一直会等到最后才做出最终的判断,得到最终的版本. 这又让我想起了之前的计算机网络的考试,我竟然这次提前交卷了!虽然这个和当时的身体问题有点关系,着急解决生理问题,但是我明显有感觉,那种想上厕所的感觉是被不断放大了的,被那一位位提前交卷的同学,被那一份自己心里的小小的开始蠢动的松懈,所鼓动,所&quot;挑拨&quot;.以前是不会这样的. 保研的结果带给了我很多之前三年没有却一直期望着的那份轻松,也让我终于可以如愿以偿的学习和探索自己中意喜爱的领域,但是也带给了我生活和意志上的松懈,对于学业功课上的粗糙/马虎. 这是我不能忍的事情.对于学习的态度,是我长久以来一直引以为傲的事情,可是,现在我却失掉了这一份立足之本,我又如何能够有多的进步和更大的收获呢? 除此之外,还想说说关于那个选修的事. 遇到了比较大的困难.本来是要上课的一门实验课,老师脑袋一热,反而建议我们参加一个比赛,正好就不用上课了...对于这个决定,很反感,因为我只想安安稳稳拿到学分,度过一段轻松的时光,没想到,出了这样的波折.比赛就比赛吧,也是各种让人不开心的事.说好的fpga板子,现在也没见到影子.也不知道怎么回事.幸好之前和老师接了一款板子.用起来有点繁琐,先得烧录一个系统到sd卡里,再启动,使用电脑网线与之相连,配置ipv4对应的配置,浏览器打开对应的ip地址就可以实现交互了.但是,过两天比赛提交作品就截止了... 我现在最烦心的是,不知道我们这个比赛要做到什么地步,才能算是满足老师的要求... 想想,本来一个也不算太难的事,若是早早就做了的话,估计也做完了,反而一直拖到了现在,弄到最后,简直是自寻烦恼. 结合之前的思考,这些其实是&quot;一脉相承&quot;的,心里的放松,思想上的松懈,对于学业的轻视,这些糟糕的,错误额态度,都是现在的状况的诱因. 说了这么多,希望算是一个小小的反思,日后再次看到这篇文章的时候,能够想起现在的状况,也会更多的注意当下的行为和心态.]]></content>
      <categories>
        <category>生活与思考</category>
      </categories>
      <tags>
        <tag>学习</tag>
        <tag>态度</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[这些衰败的日子]]></title>
    <url>%2F%E7%94%9F%E6%B4%BB-%E8%BF%99%E4%BA%9B%E8%A1%B0%E8%B4%A5%E7%9A%84%E6%97%A5%E5%AD%90%2F</url>
    <content type="text"><![CDATA[想换主题了。 一 突然心血来潮，想换主题了。搜了将近一个小时，打算用这个了。 https://github.com/rujews/maupassant-hugo 可是，hugo的基本配置，有点蛋疼啊。。折腾的心烦。 好想换回hexo了。 安安心心写点东西。 二 愈发的懒惰了，根本不想重新再搭一遍博客，费时费力，这个Jane已经很不错了，只是可能觉得略微有些偏窄，没有侧栏设计，三段式的布局。 头 -&gt; 体 -&gt; 脚 不过功能很全面，不想再改动了。 没时间，没心情，没动力了。 三 最近一直在linux下学习CS231n课程，电脑配置的劣势凸显的无比明显，jupyter notebook使用在浏览器上，本身就比较耗费资源，尤其我用的还是Chrome。 尤其在读取样本数据集的时候... 不过话说回来，Chrome用起来，在linux上确实比windows上好用些。字体发虚的问题并没有出现，清晰流畅（这个稍微有点不贴切，还是有点卡顿的），但是比firefox用起来还是好用些。 学习主要看了知乎上的《智能单元》的专栏，将以前的笔记进行了翻译，适当的也添加了自己的补充。很不错。 看的有些细节还是有些疑惑，都复制并添加补充了自己的思考和引用。希望对于自己的日后的学习能起到更多的帮助。 四 在学习课程的时候，相关的作业基于python，作业在忙第二次的，现在做到了卷积网络的部分。前面的作业还没有使用到框架，还是在手动练习，熟悉各个环节和流程的时候，这个时候趁手的编辑器和给力的补全提示操作就很重要了。 先把功能提升的首要考虑放在了jupyter notebook上了，因为作业的主文件是.ipynb文件，通过交互式的编辑方式，调用很多具体的函数的.py文件，以及类的.py文件，来实现代码的交流沟通。查了好久，知道了有一个jupyter notebook插件包，里面提供了多种功能的插件，翻译，补全的自动提示（默认需要tab），高亮选中的部分等等，各种。当然，也安装了主题，有一个主题包 jupyterthemes，提供了数种皮肤主题，默认不显示菜单，后来查了issue，原来需要指定一个额外的参数来应用主题。 用它来写notebook文件可以，但是写py文件却不是很合适，很不方便。 开始是在gnome默认的终端模拟器里，使用另一个标签页来使用vim。 vim也是配置了好久，才基本上实现了需求。但是，总是有些想法，想要使用一种能平铺的终端，最后选择了tilix。 但是vim用着还是不痛快，我考虑了Sublime text3，本身很不错，轻量但是又可以很给力，配合插件系统，很给力，但是有一个要命的问题，总是卡着闪退。 为了稳定，我又尝试了VSCode，但是，更大的卡顿的问题又来了。有时候卡死，没办法，只好另寻他路，最后，还是落在了emacs上，但是又不想使用evil，找到了一个使用原生键位的配置，很不错，尤其是主题用的是doom的配色主题。 对于python需要安装一个语言系统服务包，但是一时脑热，装到了子环境里，导致正常启动的emacs，在主环境里没法检测到这个，会报错，为此我还到作者那里提了个issue，尴尬。最后巧合下发现了这个问题，即时修改了issue。 五 这一路来，最坑的还是输入法了，最一开始并未想过换输入法，本以为ubuntu18.04自带的ibus拼音输入法感觉不错，可以一用，没想到，时间长了自己还是崩了。 此时只好想要试试搜狗输入法，但是各种问题，坑的一笔，没办法，最后还是选择了稍逊一筹的谷歌拼音输入法，还是省事些。 后来帮同学收拾了下，没想到倒也简单。只是最好不要直接双击利用ubuntu软件商店来安装，还是使用指令安装吧： sudo dpkg -i sogou....deb sudo apt install -f 我就动了心思。 没想到，到了我的机子上就坑的一笔，多番测试，还是重新装了下fcitx和搜狗，才搞定了。 测试了好久，知道了不可以取消具体的fcitx的高级选项，需要保证各项都保持好原本的状态，但是最好把那个简单的界面取消，一来确实鸡肋，因为其中大多选项选不了，二来最好把输入法的状态栏显示出来。 六 看了下《云图》，因为《如懿传》尚未更新。 裴斗娜，周迅，这就够了。 裴斗娜 裴斗娜 裴斗娜周迅 裴斗娜，之前看过她的《秘密森林》，善良、可爱，但又不失智商。笑起来和新垣结衣有着同样的魅力。 迅哥，唉，这个优秀的演员。 七 2018年9月17日23:20:53 今天重新装了下emacs。ubuntu自带的版本还是25.2，最新的正式版都是26.1了，没办法，只好编译安装了。找了好多资料，才算安上了。 wget http://mirrors.ustc.edu.cn/gnu/emacs/emacs-26.1.tar.xz tar xvf emacs-26.1.tar.xz cd ...(emacs解包路径) sudo aptitude install libgtk2.0-dev sudo apt-get install libxpm-dev libjpeg-dev libgif-dev libtiff5-dev 最好先把各种配置依赖项安装好，可以先执行一下下面的指令，会在最后提示各种依赖问题，可以查找方式解决 ./configure --prefix=/usr/local/emacs make -j4 # j的选项依赖cpu核心数 sudo make install 把emacs的安装目录加入环境变量 vim ~/.profile 添加下面这行 export PATH=&quot;$PATH:/usr/local/emacs/bin&quot; 然后执行 source /home/bboysoul/.profile 创建emacs的图标 cd /usr/local/emacs/share/applications 把下面这个文件复制到 cp emacs.desktop /usr/share/applications/ 之后注销重新登录一下就可以找到图标了]]></content>
      <categories>
        <category>生活与思考</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>琐事</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如懿，如意]]></title>
    <url>%2F%E5%BD%B1%E8%A7%86-%E5%A6%82%E6%87%BF%E5%A6%82%E6%84%8F%2F</url>
    <content type="text"><![CDATA[最近一直在看《如懿传》，如懿深陷冷宫，不知后续如何... 最近一直在看《如懿传》，如懿深陷冷宫，不知后续如何... 如懿 周迅一直是我极其喜欢的一个演员，从12年的《听风者》，到后来的《龙门飞甲》、《撒娇女人最好命》、《如果·爱》，以及如《表演者言》之类的节目，都可以感觉出来她是一个很特别的演员。 最初认识到这么一个演员的时候，是在小时候看《格言》杂志，有一篇她的文章，回忆她当年表演之路上的种种规划和努力（翻了下，找到了这篇文章——《想想十年后的自己》 十八岁之前，我是个不晓得本人想要什么的人，那时我天天就在浙江艺术学校里随着同窗唱唱歌，跳舞蹈。偶然有导演来找我拍戏，我就会很高兴地去拍，无论多小的角色。假如没有老师跟我的那次谈话，那么兴许直到今天，依然不人知道周迅是谁。... 当然，这是一篇“鸡汤文”，但是真情实感在其中，总会有能产生共鸣的时候。当年我就颇为感动，记下了这个特别的演员。 这本杂志中还提到了周迅，是讲她的《画皮》。 话说，这本杂志是《格言》杂志的第一百期的纪念刊，很厚，收录了不少文章，许多是我现在回想起来还是颇为感动的。 后来，生活水平好了些，用上了“大锅”天线，可以搜到很多以前看不到的频道，尤其是中央六台（真是好频道啊，哈哈，有多少美好的回忆~），于是便接触到了《听风者》。这是梁朝伟和迅哥一起演的一部谍战片。 周迅真漂亮啊！ 周迅 周迅 不行了，受不了了~ 这个电影，看完以后真心不舒服，极度难受，迅哥在中途就挂了，死得好惨，只记得那个镜头，一地的鲜红。豆瓣上，很多人都有同感。 这部电影，让我知道了周迅，知道了这个声音如此特别，笑容又如此可爱，而且又可以如此帅气的演员。 后来也没怎么有机会找她的电影去看，直到徐老怪的《龙门飞甲》，又一次让我看到了那个独特的周迅，帅，真的帅！ 周迅 不过此时我还不识陈坤，耀眼啊~ 陈坤 剧情记不得了，但是这部片子，算是老怪3D技术试水之作，不能不说技术上十分出彩。 机缘巧合之下，看了《撒娇女人最好命》，这个片子里，迅哥好可爱。而在最近，又看了陈可辛的《如果·爱》，感觉迅哥真的是美极了。 周迅 这么多年来，从最一开始认识了周迅这个人，到现在渐渐对她有了更多的更立体地了解，发现周迅是一个很有理想、而且很有实力的一个演员。 对她的喜爱愈发落实在心里。 《如懿传》终于开播了，拖了好久，前途不明。 但是，有周迅，我还是愿意看一下。 迅哥现在43了，依旧年轻、帅气、可爱。 这个不老的精灵，真的希望她可以永远幸福。]]></content>
      <categories>
        <category>电影与艺术</category>
      </categories>
      <tags>
        <tag>影视</tag>
        <tag>随感</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开心麻花]]></title>
    <url>%2F%E5%BD%B1%E8%A7%86-%E5%BC%80%E5%BF%83%E9%BA%BB%E8%8A%B1%E5%87%A0%E9%83%A8%E7%94%B5%E5%BD%B1%2F</url>
    <content type="text"><![CDATA[前天看了一下开心麻花的几部片子，很逗，一口气看了三部。 先看的 羞羞的铁拳 ，印象最深的上山练功那一部分。 第一次爆笑是在秀念大师兄(王成思 Chengsi Wang)示范飞身插广告的那一段，纵身一跃，以为可以潇洒自在，结果飞来横祸，惨死街头…… 漫天的广告纸，见证着大师兄的陨落…… 突然镜头转切到祠堂祭奠，笑意再也忍不住了，哈哈！ 还有一段是山上众人看电视，第一次出现的镜头，众人凝视电视，第二次出现的时候，才发现还在调电视中——原来一直没有调好…… 当然，最让我无语唯有爆笑的是第一次沈腾出场的时候，潇洒的出场，尴尬的下跪落地…… 而对于 一念天堂 ，我只记住了那个小姑娘，唱《睫毛弯弯》的那个小姑娘(何美璇 饰 兰兰)。 何美璇 饰 兰兰 夏洛特烦恼 ，说实话，以前我以为是 夏洛特~烦恼 而非实际的 夏洛特烦恼…… 这个蛮有意思，恍惚之间穿越了(?)。不过倒是印证了一个道理—— 最爱你的人，往往是最容易被忽略的。 珍惜眼前人吧！]]></content>
      <categories>
        <category>电影与艺术</category>
      </categories>
      <tags>
        <tag>开心麻花</tag>
        <tag>电影</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我不是药神]]></title>
    <url>%2F%E5%BD%B1%E8%A7%86-%E6%88%91%E4%B8%8D%E6%98%AF%E8%8D%AF%E7%A5%9E%2F</url>
    <content type="text"><![CDATA[关于《我不是药神》 序 首先庆祝下，今天算是小工作的一个里程碑阶段，生产实习的上位机的代码基本完成，就差进一步整理（清理）了。 而且终于搞定了hugo的shortcode的使用方法，具体可见之后的一篇文章 关于hugo的shortcode的使用。 关键是Jane这个主题的作者自己修改的关于豆瓣的条目的使用的一个shortcode的应用，折腾半天才搞定。 确实给力！ 想法 我不是药神 主要讲了一个吃药难的问题，印度有仿制药，中国不允许在专利期内进行仿制，只能出现片子中的尴尬局面。 卖神油的，为了赚钱走上了走私药物的道路，结识了一群身不由己、顽强生活的人。 些许小感动，浓浓市井生活气，一报还一报。 为了孩子，迫于现实，转手放弃走私药物的行当，走上了另一条更为安稳，更为正当的道路。 “来，吃个橘子。” 王传君 这句话，成了一前一后两种不同思想和认识转变的见证与激励。 王传君的表演是值得夸奖的，当当年 爱情公寓 的那帮人中的其他人，要么各种装疯卖傻，要么销声匿迹，他却走出了一条属于自己的道路，一条真正的演员的道路。吕受益这个角色，自我感觉是全片的关键，是程勇的转折的推动点，而他的表演，完美的做到了这一点。 钢管舞——性感背后是汗水 谭卓 谭卓饰演的单亲妈妈刘思慧，一段钢管舞，惊艳、性感，但是这之后是无限的努力。片中，徐峥饰演的程勇，用钱砸经理让他跳钢管舞的那一刻，真心解气，刘思慧眼中的泪水，或许才是真实的生活。 黄毛剃光头 章宇 章宇扮演了黄毛彭浩，这是一个特别的角色，社会底层，这种人生了大病，就是玩命。没招。 山争，给力 徐峥 徐峥现在可是出了大名，各种片子，评价都不错，不论眼光，不论演技，都是票房保证。 最后 对于电影本身的各种技术性评价，我不懂，但是我知道，这部片子，绝壁是值得赞扬，值得五星好评的。 对于现实问题的反映，是艺术源于生活、高于生活的一种特性。 可是现在的这些片子，都是些什么玩意儿。 我等民众，开心就好。]]></content>
      <categories>
        <category>电影与艺术</category>
      </categories>
      <tags>
        <tag>佳片</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[风吹过玉兰]]></title>
    <url>%2F%E5%B0%8F%E8%AF%97-%E9%A3%8E%E5%90%B9%E8%BF%87%E7%8E%89%E5%85%B0%2F</url>
    <content type="text"><![CDATA[配图 参加活动，造诗一首。 思绪反复，闹人，恼人。 123456789101112131415161718192021222324252627风吹过玉兰雨击打边栏摇摇晃晃 不断群星闪闪已向晚银杏叶呼扇呼扇搅动整个夏夜雨后金黄遍地人影匆匆不见影踪迷离夜色下呼吸这恼人的夏摇头摇头甩一把泪别过了头连理 理连着愁意浓浓 笑吟吟喜相逢 愁别离踏踏清脆脚步声是不悔的青春]]></content>
      <categories>
        <category>幻想与现实</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>校园</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一千天的时候]]></title>
    <url>%2F%E6%95%85%E4%BA%8B-%E7%AC%AC%E4%B8%80%E5%8D%83%E6%97%A5%2F</url>
    <content type="text"><![CDATA[飞翔的鲸 第一千天的时候 by 庞有伟 一 今天是我们共处的第420天。 一年多以前，我花了一大笔钱，从那个落魄科学家那里得到了她。 那时他正要离开这个国家，急需出手这些带不走的东西。而我却因为没有离开的渠道，只好准备了另一种生活的方式。 哦，应该说是——苟活的方式。 我拿到了他们的一些补偿，被安置在了原来废墟不远处的新城。虽说新城，实为旧时拆迁尚未拆掉的旧楼。但是水电齐全，尚可安顿。 有时候和她坐在一起，我就在想，这会不会是个梦？ 倒真像个梦啊。 他们那时已经打了好几个月了。战争总是激烈的，死了好多人。 邻居家老太太的小孙子，多么可爱的一个小孩子，刚要准备上小学，却说没就没了。还有街角超市的那个漂亮的姑娘，她好像年末就要结婚了吧？ 当然，还有我们家里的人，以及，她的一切。可惜，我活着。 看着坐在前面的她，不禁一阵恍惚，鼻头骤然骤然一酸，眼泪又止不住的流了出来。 她递过来了一张纸巾。 我看向了她。她的眼睛里泛着光，那是屋里灯的光。光芒背后的颜色却是真的好看，是那种令人心静的蓝色。 那个科学家，还是很有想法的。也不知道他现在怎么样了。估计也一般吧？ 看着她，心里有些异样，但是说不上来。 屋里很暗，仅有几盏灯亮着。家里窗帘很厚，足以隔绝一切。 我已经准备好了所有东西。 我笑了笑，伸手顺了顺她的头发。 她也笑了。 二 这是我们相遇的第500天。 记得我们刚刚相见的时候，说了好多的话。不过，若是说具体说了些什么？ 哈哈，已经记不得了。毕竟都过了这么久了。 是啊，这么久了。该说的都说了，便就没话说了。 毕竟，她只是个机器人。 看着坐在对面充电的她，我心里忽然有点不开心。 但是每当我抬起头来，看到那张熟悉的面孔，就会觉得有一股难言的情绪弥漫在心里。 记得当初，她也是类似的姿势，坐在我的面前吧？ 战争啊。战争，唉。 看着紧闭着的窗帘，目光一滞，便又转开了。自那之后，这帘子就没有打开过。不喜欢太阳。因为感觉那刺眼的光，砸在心上，好生冷漠。 第500天的夜和第499天的夜一样，去的轻轻，来的匆匆。 屋外传来一些脚步声和低声细语。估计又是在讨论着当前的局势。 这个房间，应该会安全一阵子的吧。 外面是什么样子，我已经不知道了。 但是，那重要么？ 记得战争刚开始的时候，她就和我说过，要是有事，就赶快跑，越远越好，最好离开这个国家。可是谁又能离开呢？ 后来，局势越来越混乱，难民也越来越多。这个国家里，能去的地方，也没有几处。没想到我们倒是又挤在了一起。 那是个尴尬的时刻，双方家里人那时倒都还在，互相打过了招呼，也就没有再说话。 只记得，在离开的时候，她回头看了我一眼。当时的情形，已经记不清楚。但是，那一次回头，却让我再也忘不了了。 忘不了了，因为一切都终止于此。 戛然而止。 敌人的战机飞过了这里，他们的炸弹质量不错，嗯，确实，就是没炸死我。 但是，为什么却让其他人都死了？可是，这个问题，我该问谁？ 没得问，就没的说咯。 已经到了夜晚，依旧留着一缕光。 半夜里往往会醒过来，没有了这缕光，很不踏实。那次事情留给我的礼物，或许也就是这做噩梦的义务了。 第800天，转眼就到了，就像之前的第700天那样。 看着墙上密密麻麻的“正”字，整整齐齐排了40行，竟有了一种说不出的成就感。 成就感，虽然有点夸张的感觉。但是在这个时间点，倒也确实可以说得上是一种“成就”了。 但是总是隐隐的有些感觉——只是感觉说不清楚——让人很不安稳。 噩梦更加频繁了。 三 这是第999天的结束，亦是第1000天的开始。 新的生活又将开始。 所有的一切都将获得新生。 我还没有睡。今天估计是不会睡了。 把自己埋在沙发里。看着端坐在那里的她，心里有种说不出来的难过。 每天都在回想着过去一切。每次看到她，想到的也是过去。真也不知道这样的生活究竟有怎样的意义。 苟延残喘？白日做梦？ 站起了身子，走向了这个已经陪伴了我已经九百九十九天的“人”。看着她完美的皮肤和身材，我已经没有了最初时那样的满足与幸福。 记得最开始的时候，即使是坐在那里，静静地看着她，什么也不做，也是无尽的欢喜。 在她的“生命”的最开始的时候，我从她身上获得了新的快乐与激动。那种久违的，总被我觉得早已丢失了的情感，自从见到了她，仿佛一切都活络了过来。 这该以怎样的状态来形容呢？ 仿佛就像是被丢弃在了一片荒野后，发现周边什么生命也没有，只有自己一个人在苦苦挣扎。忽然有一天，有了一个新的、可以和你说话的——尽管大多数是我问她答——类似于“人”的生命个体，来到了你的身边…… 感觉一下子，一切都开始有了色彩。 想着这些混乱的东西，手已经摸到了她的脸颊。 此时的她是没有意识的，今天她已经活动了太久，储备的电能早已消耗干净了。 她的脸上的皮肤，软软的，绵绵的。触感很好，各方面都是完美的。可是却唯独有一点，却让我一直会在摸着她的皮肤时，不自觉地在脑子里跳出来“她不是人，她是机器人”的想法。 ——她的皮肤没有温度。 手已经探到了她身后的电源插口上。没有什么迟疑，顺着就把电源拔了出来…… 看着她的脸，我脑袋空空的。 回过头，顺手把窗帘扯开了。 天正亮。 一缕微光在窗帘拉开的同时，急不可耐的冲了进来，而紧随其后的无数光芒，瞬间席卷了整个房间。 远处的朝阳正雀跃着，欢呼着。仿佛在竭尽可能得为她的新客人展示着自己的所有的美。 就是这一天了，广播里说的就是这一天。 遥远的天空中，一点光芒急速飞近…… 随后，整个世界都安静了。]]></content>
      <categories>
        <category>幻想与现实</category>
      </categories>
      <tags>
        <tag>科幻</tag>
        <tag>爱情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017年总结]]></title>
    <url>%2F%E7%94%9F%E6%B4%BB-%E4%BA%8C%E9%9B%B6%E4%B8%80%E4%B8%83%2F</url>
    <content type="text"><![CDATA[一 2017年转瞬即逝，倏忽间，便已是2018。 回顾2017，我所希望的目的是，可以找到自己的不足，找到更多的缺点，找到，那个熟悉的自己。 二 人生天地之间，若白驹之过隙，忽然而已。 一七年，是鸡年，我已经忘了春晚是什么样子，我也忘了年初那个寒假，是如何度过的。 一七年，已经陷入了遗忘的轮回。所有的色彩都在变得稀薄，所有的味道都在变得寡淡，所有的人影都在变得模糊。 记忆的长廊里，愈发的在被新时光填充，新的色彩绘成了新的画面，挂在了墙上，新的声音汇成了新的曲调，飘荡在空气中。 这一年里，过得匆忙，还没反应过来，就已经到了年末，新的年初。 这一年，学了好多的课程，但是印象最深的不过计算机原理和随机信号分析，主要是因为和这两门课的老师联系比较密切。给他们留下了比较好的印象。 接触了8086汇编，学到了计算的组成所涉及到的方方面面，顿时对于眼前所面对的这个东西多了一份熟悉感。 之后会整理一下汇编语言的知识。 随机信号重新温习了一遍概率论的知识，但是却总是感觉流于表面，在学习的过程中，总是有一层纱，一直笼罩在我的面前，戳不破，点不透。模模糊糊，就这样在最后的考试中，以一个96作结。 对于一七年上半年，已经没了任何印象。而下半年，主要是开始摸到了考研的边缘，生活节奏顿时快了许多，也更加单调了许多。放弃了很多的事情（其实实际上而言，不算放弃，只是更加的不再主动），将所有的精力放在了学习上，从最开始的独飞，到考试前的集体自习，不断感受着“强者们”的强，学习的事，靠的是自己，但是考试的事，却在此时，无比显然的凸显着集体的力量。 更多的考试习题，被“强者们”从各种渠道搞来，只有你身为其中的一分子（是“一分子”，而非“一份子”）的时候，你才能感受到独自作战时捉襟见肘的无奈。 唉，这个社会…… 三 一七年看了好多电影和电视剧。 国内的： 段奕宏的《引爆者》 有很多背景与与我的家乡相似 那绚丽的烟花，是愤怒与无奈 潘粤明的《白夜追凶》 近年来，国产剧的最大惊喜 大鹏的《缝纫机乐队》 让我改变了对于《屌丝男士》的大鹏的低俗印象，里面的音乐确实好听。 不思凡的《大护法》 犀利 周冬雨的《喜欢你》和《七月与安生》 自此喜欢上了这个肤白貌美，笑起来眼睛都不见了的姑娘。 她的笑容，看着就开心。 …… 亚洲的： 今敏的《东京教父》 似乎是今敏唯一一部比较温情的电影。 “京アニ”（京阿尼，京都动画）的《声之形》 好虐呀，虽说有点矫情。 配乐很好听。 新海诚的《你的名字》与《言叶之庭》 真，漂亮，的画面。 配乐，画面双绝。 宫崎骏的《起风了》 好看，没话说。 理想，爱情。 阿米尔·汗的《摔跤吧，爸爸》 对社会现实的批判，对于女性的鼓励与尊重。 押井守的《攻壳机动队》(1,2) 吊吊吊，没话说，逼格，就是逼格。 …… 欧美的： 雷德利·斯科特的《银翼杀手》 黑暗，压抑，细节丰富，画面色彩独特，内涵深刻 维伦纽瓦的《银翼杀手2049》 压抑，色彩更炫丽，依旧不失深度，对于自我身份的认知的不断反转，最后感觉好可怜 诺兰的《蝙蝠侠：黑暗骑士三部曲》和《敦刻尔克》 非线性叙事玩出了花。 前者黑暗骑士，另类的英雄，独具特色的反派与配角。牛逼的小丑。 后者以另类的方式讲述战争。 埃德加·赖特的《极盗车神》 没有了音乐，这部片子就没意思了。 有了音乐，这部片子就神了。 盖尔·加朵的《神奇女侠》 盖尔·加朵好美呀！ 张艺谋的《长城》 好一部怪兽围城。 周杰伦、摩根·弗里曼的《惊天魔盗团2》 杰杰六六六。 克里斯·埃文斯（美队）的《天才少女》 温情，感人。 小姑娘让我想起了《怒火救援》里的达科塔·范宁。 斯嘉丽·约翰逊的《唐璜》 嘿嘿嘿…… 埃米纳姆的《八英里》 姆爷的曾经过往。 女主挺漂亮。 说唱很犀利。 …… 看了不少，主要以电影为主，幸好有PT资源站，感谢IPV6，让我们身处校园内，可以免费获取那么丰富的资源。 感谢这些片子，给了我美好的回忆。 四 一七年，比较值得纪念的一次旅行——去了一趟长沙。 飞机飞济南，火车直奔长沙。 这是两个“第一次”——第一次坐飞机，第一次坐火车。 以前对于飞机的感觉就是高大上，机票贼啦贵，一般不愿意坐飞机，更多是选择火车。但是这次受地理条件以及时间所限，坐飞机是一个比较合适的方式，否则就要绕好大一圈的渤海湾。 大连真是祖国的“犄角旮旯”呀！ 头一次感受到了卧铺的方便与舒服（相较于硬座而言），四个人，一起嗨。他们仨玩扑克，我玩了几把就不想玩了。不太喜欢这一类游戏，总感觉没意思。不过，辛好我带了本书，《灿烂千阳》，去时看了一路。 这一路上，我们看过了白云拥挤的沉在我们的下方，看过了云雾缭绕的泰山在我们的窗外耸立，看过了从南到北的各色人潮，或多或少的认识到了，所谓的地大物博。 南方真热，尤其是在北方已经开始热起来的时候。到了长沙，最先做的就是洗澡。带了两天，洗了两次澡，其他时间就在吹空调。 第二天晚上，一切结束了，就出去和小伙伴们吃了一顿红烧肉，米饭免费供应。感觉很棒，肥而不腻，又香又辣，吃的我们爽个不停。 次日，就准备回学校了。在上火车之前，我们上了橘子洲头，见到了毛爷爷的巨大塑像。那时大家已经是湿透了，全是汗。在走向洲头的时候，感觉衣服将皮肤摩擦的疼痛无比。大家是叫苦不迭。太热了。但是为什么还是那么多的人？ 橘子洲头毛爷爷塑像 绕了个大圈。绕道开封。刚听说要到开封，就在想，开封会是什么样的一个城市。但是经过数个小时颠簸又熬夜的硬座，到了之后，有一种“幻想破灭”的感觉。 感觉回到了自己老家那个小县城。乘兴而来，失望而归。无奈。 十几个小时的卧铺之后，终于回到了学校。终于可以回家了。 这几十个小时的颠簸旅程，倒是成了我日后被学习压得喘不过气来的时候，可以偶尔回头细品的一段记忆。 五 一七年，过去了，就像他来的那样，匆匆，去也一般。 一八年，来了。]]></content>
      <categories>
        <category>生活与思考</category>
      </categories>
      <tags>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[麦兜，幸福的麦兜]]></title>
    <url>%2F%E5%BD%B1%E8%A7%86-%E9%BA%A6%E5%85%9C%E9%A5%AD%E5%AE%9D%E5%A5%87%E5%85%B5%2F</url>
    <content type="text"><![CDATA[这篇文章拖了好久。借此闲暇之时，写些自己的看法。 之前并未看过麦兜的其他片子，但是在高中的时候，经常看一些作文素材，会接触到许多的零零碎碎的世界之事，其中，麦兜也是这时候了解的。 似乎那是讲“麦兜之父”谢立文的故事。 印象中对于麦兜的记忆片段，似乎是麦兜成了宇航员，飞上了天空，也有麦兜妈妈的影像，只记得当时的场景很煽情，很催泪。 而这次的麦兜饭宝奇兵，不得不说，有笑点，有泪点，不过，终究是笑点更多，略带幻想的有丢丢励志的人类大战外星怪的搞怪动画。 影片开头，主要讲了外星怪物袭击地球，人类各种手段都无法战胜，甚至来自宇宙的扎肉超人都被打败。此怪兽，力大，体壮，能力强，无坚不摧，无法被战胜。 无奈的人类，只好寻求全世界的力量。最终麦兜的饭煲机器人成了人类的救星，和怪兽一起回到了怪兽的星球。拯救了地球。 全片极具恶搞意味。 扎肉超人的那句“s-o-o-r-y”以及被怪兽打回了家后面对家人的说辞；麦兜家乡邻里的言语交谈；麦兜最初那不切实际的各种创新想法；隐士高人的献身；机器人战斗之间的搞怪；怪兽的摇摆舞，高能臭气，无敌屎尿屁（。。。）；世界级富豪赤膊上阵造机器人；政府高官一心想用自己的机器人假意办比赛；等等。 各种普通人之间的温馨暖意，也有战斗双方的心怀恶意，还有理想梦想的闪烁耀眼，也有对于灾难的恶搞性表达。这些片段，各种各样的搞笑，实际有着不同的真实感情。终究还是人情，人心。 但是，打动我的，不只是这些并不流于表面的恶搞逗趣，而是片子很是重点描绘的感情。母子情，友情，以及一种有点略微浮夸的普世情怀（个人感受）。 而其中，主要让我感动的还是母子情。 毕竟，这种情感如何“浮夸”都不为过。 妈妈为了帮助儿子实现梦想，拼命地做鱼丸卖鱼丸那一段，还是很感动的。母亲作为一个普通人，想要赚到钱，而自己也只会做鱼丸，所以也就只能卖鱼丸，棒槌在肉上锤来锤去，漆黑的夜里，闪亮的灯点亮的不只是飞溅的汗水，还有一位作为母亲的伟大的灵魂。 再说说麦兜的饭煲，就是一个电饭煲，但是却有着极为出众的适应能力。可以自我供能——自己给自己做饭吃。（都是吃货）。而正是这种小强般的生命力，才使得他不断地战胜敌人，保护地球。 不过，编剧的脑洞还真大，电饭煲配洗衣机——饭煲机器人，操纵洗衣机。。。 这片子，大脑洞，大恶搞。 看的感觉还是蛮爽，有笑点，有泪点。 适合私人观看。]]></content>
      <categories>
        <category>电影与艺术</category>
      </categories>
      <tags>
        <tag>影视</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二零一六]]></title>
    <url>%2F%E7%94%9F%E6%B4%BB-%E4%BA%8C%E9%9B%B6%E4%B8%80%E5%85%AD%2F</url>
    <content type="text"><![CDATA[新的一年，大迷茫，小欢喜 二零一六年就这么在喧嚣中过去，期间的种种思忧，愈发的折磨着我的内心。 和同学的矛盾愈演愈烈，对于既有任务的抗拒与拖延，对于新事物的好奇与探索欲望，喜新厌旧的毛病，一直在。 每天病态的翻来覆去，思来思去，总想找到最舒服的最省力的方式学习与进步，可是世界上又何来两全其美？ 喜欢技术，却从未有过深入，爱好广泛，却并未有一项精熟。细细想来，好高骛远，无法脚踏实地，或许是最大的毛病。 一番折腾，倒是做了一点事。 自从放假回来，sublime一直在用，主要是在写md文件，配合着csdn的markdown写着博文，当然，主要还是翻译。翻译阅读了bhuman的文档的视觉部分的自己的分工的部分。不是太懂，但是看着自己的翻译出来的文字还是蛮有成就感，由于bhuman这个体系太过庞大，操作起来有点麻烦，阅读代码的崩溃心情，以及长时间的懵逼，想想三月就要参加比赛，心情很糟糕，烦躁，忧虑。越来越没有兴趣。只好转战其他方面。 长久以来，有一门编程语言，在我的心里有着很高的地位，就是C++。我倒是很想学会它，但是，C++的浩瀚又岂是我这个半吊子可以轻易熟透的，连基本的语法都不曾理解，又何来熟悉。由于相关的技术书籍都是那么令人望而生畏，本着极简至上的原则，我找到了一个网站，上面有C++的基本知识，但都介绍的很简短，对于我的目的正好符合。于是就开始了几天的复制粘贴，阅读删减的生活，蛮有动力，一些以前不明白的概念也有了一些理解，并且有了一点小小的冲动，我要写东西。 后来找到了实验楼这个网站，蛮不错的，里面有着各样的实战案例，要求用户按着说明一步步完成任务，帮你熟悉linux的基本操作，以及文本编辑器vim，gedit的使用，当然也有一些常见命令的使用。印象最深的就是（实际上我就参与了那个C++的案例）利用openGL搞出一个太阳系的模拟图，三维的。很叼，很流弊，以前关于C++的大型库就接触过openCV，但是最近一直没有碰过，借此机会有好好感受了一下，创造的魅力。 很喜欢编程，感觉编程就像是在创造，创造一个新的世界。 我有一段时间特别迷恋一个游戏，minecraft，我的世界，钟情之处，就是因为其自由，无所不能的可创造的世界！真心佩服这个游戏的制作者，如此大的胸襟，如此开阔的思维，如此具有创造力的项目！ 我很喜欢手摸键盘的感觉，手指在键盘上滑动敲击，欢喜于那种行云流水，那种自我创造。 不过，还是有些心烦，又转向了其他的方向，无所事事的在网上流浪。 忽然之间想起了之前看电视听说的一个语言——chuck，一个音乐编程语言，出于种种自我原因，想要尝试一下，就找到了官网，下载，安装，测试，这一点点知识，网上倒是有位博主有点相关内容，不过就是一些简单的基本知识，之后便没有了，我想，人家也只是出于一时的兴起吧。而我也正在兴头上，就准备看看。于是接下来的几天，我减少了上网娱乐的时间，一心去看那些满屏的英文字母，带着有道翻译，一页一页看下去，慢慢的就搞了十几篇翻译的博文，当然，有不明白的地方，还是很多。基本的手册上的语法内容，过了一遍，里面有C++/C的影子，当然，也可能有JAVA的影子吧，但是这些对于使用它而言，还是不够。机缘巧合，在一个极有开源精神的技术书籍共享博客里，找到了一本chuck网站推荐的一本由原作者们所出版的一本书籍，虽然是纯英文，但是我感觉到了前进的方向。 对于音乐，我有着自己喜好，各种调调，各取所爱。但是假如可以自己创造音乐，那该是何等的happy！这个欲望，感觉在这几天里，很是强烈。 这几天里，看了好几部剧，所涉内容还是很贴地气，讲了日常的生活，工作，学习，为人，处事，交友，感觉很是受感染。印象最深的还是一部讲实习生生活的剧。感觉很真实（只是指它的内容所关联的现实），毕业生的人数之多，就业之难，初入职场工作之难，家庭生活之难，每个人都有难言之隐，每个人都有负担，每个人都有着一份小小的欲望。但是，我们还是应该坚持自己。 其中有一句很好的台词，“ 我们生下来，就注定改变世界，但是我们千万要记住，就是一定不要变坏，不要变成我们年轻时，最痛恨最厌恶的那种成年人。哪怕有十万种理由让你去做恶，你都要保持自己的操守和底线，做一个正直的人，做一个善良的人，做一个能改变社会的人。”说的真的很好，做一个正直善良的人。 我也曾幻想着未来，可以有更完美的技能，用自己的双手，创造着价值，为周围的朋友，家人，可以提供一份力所能及的帮助和支援。 我也曾期待着明天，可以有流畅的英语，更熟练的知识，用自己的大脑，改变着自己的人生。 这么多天的忙碌。也不知道是否会成为我这一生短暂的一个小小浪花，还是一个小小的转折。 回头想想，还是一堆乱麻，无从下手，但是，终归是有些收获的，这倒是可以开心一点。 啰啰嗦嗦，没想到写了这么多……]]></content>
      <categories>
        <category>记录与总结</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>生活</tag>
      </tags>
  </entry>
</search>
